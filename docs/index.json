[
{
	"uri": "https://hajsong.github.io/ATM4110/visual/lines/",
	"title": "Lines",
	"tags": ["matplotlib", "plot"],
	"description": "",
	"content": " Line plots are created by the pyplot plot function. I think it is helpful to use the example to explore the matplotlib\u0026rsquo;s plot command. Let\u0026rsquo;s imagine we want to see the trend of global air temperature. Then one of the best way to show the trend is a line plot against the time.\nDraw lines using the data In this example, we will plot the time series of air temperature using the dataset from HadCRUT4\nimport numpy as np import matplotlib.pyplot as plt from netCDF4 import Dataset, num2date %matplotlib qt # Figures in a separate window # %matplotlib inline # Figures in this browser  UsageError: unrecognized arguments: # Figures in a separate window  Read the temperature data We are going to read two datasets: one for the mean temperature (absolute.nc) and the other one for the time series of temperature anomaly (HadCRUT.4.6.0.0.median.nc).\nf = Dataset('absolute.nc', 'r') print(f.variables.keys()) T = f.variables['tem'][:] # monthly data lon = f.variables['lon'][:] lat = f.variables['lat'][:] f.close()  f = Dataset('HadCRUT.4.6.0.0.median.nc', 'r') print(f.variables.keys()) Tanom = f.variables['temperature_anomaly'][:] time = f.variables['time'][:] # print(f.variables['time']) f.close()  The trend of the global temperature. First we want to see the time change of the global temperature anomaly.\nLet\u0026rsquo;s compute the global mean of temperature anomaly.\n[nt, ny, nx] = Tanom.shape # Dimension size mTanom = np.mean( np.mean(Tanom, axis=2), axis=1)  f = plt.figure(1) # Number is assigned to the window plt.plot(time, mTanom)  The plot shows the increasing trend of the global mean temperature.\nBut, the time axis is not easy to interpret, maybe because it is in the unit of second?\nLet\u0026rsquo;s check.\nf = Dataset('HadCRUT.4.6.0.0.median.nc', 'r') Tunit = f.variables['time'].units Tcalendar = f.variables['time'].calendar print(Tunit, Tcalendar) f.close()  days since 1850-1-1 00:00:00 gregorian  If we convert the unit from days to years, that makes the plot easier to read.\nThis means that we need to either change the unit or touch the x-axis.\n1. Change the time unit The module netCDF4 provides a handy function called num2date. Using this function, the float numbers for time become a new type called datetime.\nTdate = num2date(time, Tunit, Tcalendar) # At least 2 arguments are required.  print(Tdate[0], type(Tdate[0]))  1850-01-16 12:00:00 \u0026lt;class 'datetime.datetime'\u0026gt;  This datetime type variables can dump out year, month and day with methods called year, month and day, respectively.\nTo see the full list of methods and attributes, try dir(Tdate[0]).\nf = plt.figure(2) plt.plot(Tdate, mTanom)  [\u0026lt;matplotlib.lines.Line2D at 0x13f6ee2e8\u0026gt;]  2. Change the x-axis We can directly modify the x-axis using the axis object.\nf = plt.figure(3) plt.plot(time, mTanom)  [\u0026lt;matplotlib.lines.Line2D at 0x13fd49668\u0026gt;]  # new x axis ax = plt.gca() ix = np.arange(0,nt,240) ixlabel = time[ix]/365 + 1850 ax.set_xticks(time[ix]) ax.set_xticklabels(ixlabel.astype(int)) ax.set_xlabel('year') ax.set_ylabel('T anomaly (degC)') ax.set_title('Time series of T anomaly, HadCRUT4')  Text(0.5,1,'Time series of T anomaly, HadCRUT4')  More than one lines in one plot At this time, let\u0026rsquo;s separate the temperature trend into global, northern hemisphere and southern hemisphere.\n# T in the northern hemisphere inorth = np.where(lat\u0026gt;0) T_nh = np.mean(np.mean(Tanom[:, inorth[0], :], axis=2), axis=1)  # T in the southern hemisphere isouth = np.where(lat\u0026lt;0) T_sh = np.mean(np.mean(Tanom[:, isouth[0], :], axis=2), axis=1)  T_nh.shape  (2025,)  f, ax = plt.subplots(1, 1, figsize=(12,6)) ax.plot(Tdate, mTanom) ax.plot(Tdate, T_nh) ax.plot(Tdate, T_sh) ax.set_xlabel('year') ax.set_ylabel('T anomaly (degC)') ax.set_title('Time series of T anomaly, HadCRUT4')  Text(0.5,1,'Time series of T anomaly, HadCRUT4')  You can plot every lines with a single command\nf, ax = plt.subplots(1, 1, figsize=(12,6)) ax.plot(Tdate, mTanom, Tdate, T_nh, Tdate, T_sh) ax.set_xlabel('year') ax.set_ylabel('T anomaly (degC)') ax.set_title('Time series of T anomaly, HadCRUT4')  Text(0.5,1,'Time series of T anomaly, HadCRUT4')  As you can see, you can keep adding lines on top of others. But, it is already hard to tell which one is which.\nLet\u0026rsquo;s plot each line differently.\nYou can get the full list of markers from here, and line-style from here.\nf, ax = plt.subplots(1, 1, figsize=(12,6)) ax.plot(Tdate, mTanom, '.', Tdate, T_nh, '^', Tdate, T_sh, '*') # ax.plot(Tdate, mTanom, '-', Tdate, T_nh, ':', Tdate, T_sh, '--') ax.set_xlabel('year') ax.set_ylabel('T anomaly (degC)') ax.set_title('Time series of T anomaly, HadCRUT4')  Text(0.5,1,'Time series of T anomaly, HadCRUT4')  Or we need to label them.\nf, ax = plt.subplots(1, 1, figsize=(12,6)) ax.plot(Tdate, mTanom, label = 'global') ax.plot(Tdate, T_nh, label = 'NH') ax.plot(Tdate, T_sh, label = 'SH') ax.legend() ax.set_xlabel('year') ax.set_ylabel('T anomaly (degC)') ax.set_title('Time series of T anomaly, HadCRUT4')  Text(0.5,1,'Time series of T anomaly, HadCRUT4')  f, ax = plt.subplots(1, 1, figsize=(12,6)) ax.plot(Tdate, mTanom, label = 'global') ax.plot(Tdate, T_nh, label = 'NH') ax.plot(Tdate, T_sh, label = 'SH') ax.legend() ax.set_xlabel('year') ax.set_ylabel('T anomaly (degC)') ax.set_title('Time series of T anomaly, HadCRUT4')  Text(0.5,1,'Time series of T anomaly, HadCRUT4')  It may be helpful to read if the lines are thinner than this and in different colors. (The full list of available colors can be found here)\nf, ax = plt.subplots(1, 1, figsize=(12,6)) l1 = ax.plot(Tdate, mTanom, color='black', linewidth=0.5, label='global') l2 = ax.plot(Tdate, T_nh, color='dodgerblue', linewidth=0.5, label='NH') l3 = ax.plot(Tdate, T_sh, color=np.array([189, 48, 57])/255, linewidth=0.5, label = 'SH') # l3 = ax.plot(Tdate, T_sh, color='#BD3039', label = 'SH') ax.legend() ax.set_xlabel('year') ax.set_ylabel('T anomaly (degC)') ax.set_title('Time series of T anomaly, HadCRUT4')  Text(0.5,1,'Time series of T anomaly, HadCRUT4')  It is still not easy to see all the lines,\nintv = 6 # every 6 month f, ax = plt.subplots(1, 1, figsize=(12,6)) ax.plot(Tdate[::intv], mTanom[::intv], color='black', label='global') ax.plot(Tdate[::intv], T_nh[::intv], color='dodgerblue', label='NH') ax.plot(Tdate[::intv], T_sh[::intv], color=np.array([189, 48, 57])/255, label = 'SH') # l3 = ax.plot(Tdate, T_sh, color='#BD3039', label = 'SH') ax.legend() ax.set_xlabel('year') ax.set_ylabel('T anomaly (degC)') ax.set_title('Time series of T anomaly, HadCRUT4')  Text(0.5,1,'Time series of T anomaly, HadCRUT4')  I want to make this plot more charming.\n# Remove the plot frame lines. f, ax = plt.subplots(1, 1, figsize=(12,6)) ax.spines[\u0026quot;top\u0026quot;].set_visible(False) ax.spines[\u0026quot;bottom\u0026quot;].set_visible(False) ax.spines[\u0026quot;right\u0026quot;].set_visible(False) ax.spines[\u0026quot;left\u0026quot;].set_visible(False)  # Ensure that the axis ticks only show up on the bottom and left of the plot. # Ticks on the right and top of the plot are generally unnecessary chartjunk. ax.get_xaxis().tick_bottom() ax.get_yaxis().tick_left()  # Limit the range of the plot to only where the data is. # Avoid unnecessary whitespace. ax.set_ylim(-2, 2)  (-2, 2)  # Provide tick lines across the plot to help your viewers trace along # the axis ticks. Make sure that the lines are light and small so they # don't obscure the primary data lines. intv = 6 # every 6 month for y in np.arange(-2, 2.1, 0.5): ax.plot(Tdate[::intv], [y] * len(Tdate[::intv]), \u0026quot;--\u0026quot;, lw=0.5, color=\u0026quot;black\u0026quot;, alpha=0.3)  # Remove the tick marks; they are unnecessary with the tick lines we just plotted. ax.tick_params(axis=\u0026quot;both\u0026quot;, which=\u0026quot;both\u0026quot;, bottom=\u0026quot;off\u0026quot;, top=\u0026quot;off\u0026quot;, labelbottom=\u0026quot;on\u0026quot;, left=\u0026quot;off\u0026quot;, right=\u0026quot;off\u0026quot;, labelleft=\u0026quot;on\u0026quot;, labelsize = 12)  /Users/hajsong/miniconda2/envs/py36/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead. warnings.warn(message, mplDeprecation, stacklevel=1)  ax.plot(Tdate[::intv], mTanom[::intv], color='black', label='global') ax.plot(Tdate[::intv], T_nh[::intv], color='dodgerblue', label='NH') ax.plot(Tdate[::intv], T_sh[::intv], color=np.array([189, 48, 57])/255, label = 'SH') ax.legend()  \u0026lt;matplotlib.legend.Legend at 0x143293da0\u0026gt;  "
},
{
	"uri": "https://hajsong.github.io/ATM4110/linux/shell/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": " To get the most out of Linux, you should become proficient in using the shell. It might initially be more difficult than icons and menus, but once you\u0026rsquo;re used to it, the shell is quite easy to use and very powerful.\nHow to run a shell If you have Linux, running a shell is just opening Terminal or something similar to it. However, if you are running Windows (I think this is the most case), then you can experience Linux with the third-party program like MobaXterm.\nThis program offers a shell environment and (I think) you can do most of the common tasks of Linux with it.\nPlease get this (free) and set up in your computer.\nQuick start Once you install MobaXterm, go to \u0026ldquo;Session\u0026rdquo; and select \u0026ldquo;Shell\u0026rdquo;. This will open the terminal in bash shell environment.\nYou can check your shell environment by typing the follow command.\n$ echo $SHELL  This will give you /bin/bash.exe.\nTo finish a shell You can come out of the shell by exit.\n$ exit  "
},
{
	"uri": "https://hajsong.github.io/ATM4110/syllabus/",
	"title": "Syllabus",
	"tags": [],
	"description": "",
	"content": "   Week Date Content Note     1 2018-09-01\u0026ndash;2018-09-07 A short introduction to the linux operating system 개강   2 2018-09-08\u0026ndash;2018-09-14 A short introduction to the working environments 수강신청 확인 및 변경   3 2018-09-15\u0026ndash;2018-09-21 Python: Basic data and control structures I    4 2018-09-22\u0026ndash;2018-09-28 Python: Basic data and control structures II 추석연휴   5 2018-09-29\u0026ndash;2018-10-05 Python: Array operations I 수강철회, 개천절   6 2018-10-06\u0026ndash;2018-10-12 Python: Array operation II 한글날   7 2018-10-13\u0026ndash;2018-10-19 Midterm    8 2018-10-20\u0026ndash;2018-10-26 Atmospheric data structure: File input and output    9 2018-10-27\u0026ndash;2018-11-02 Visualization I : Plotting methods    10 2018-11-03\u0026ndash;2018-11-09 Visualization II : Make plots on maps    11 2018-11-10\u0026ndash;2018-11-16 Data processing I : statistical analysis    12 2018-11-17\u0026ndash;2018-11-23 Data processing II : temporal analysis    13 2018-11-24\u0026ndash;2018-11-30 Data processing III : spatial analysis    14 2018-12-01\u0026ndash;2018-12-07 Data processing IV : spectral analysis    15 2018-12-08\u0026ndash;2018-12-14 Final presentation 자율학습 및 기말시험   16 2018-12-15\u0026ndash;2018-12-21 Final exam week 자율학습 및 기말시험    "
},
{
	"uri": "https://hajsong.github.io/ATM4110/visual/2dplot/",
	"title": "2D Plots",
	"tags": ["imshow", "pcolormesh", "contour"],
	"description": "",
	"content": " You can download the jupyter notebook file.  Drawing 2D figures In this lecture, we will make 2D figures\nimport numpy as np import matplotlib.pyplot as plt from netCDF4 import Dataset, num2date import matplotlib # %matplotlib qt # Figures in a separate window # %matplotlib inline # Figures in this browser  Read the temperature data We are going to read two datasets: one for the mean temperature (absolute.nc) and the other one for the time series of temperature anomaly (HadCRUT.4.6.0.0.median.nc).\nf = Dataset('absolute.nc', 'r') print(f.variables.keys()) T = f.variables['tem'][:] # monthly data lon = f.variables['lon'][:] lat = f.variables['lat'][:] f.close()  odict_keys(['tem', 'lat', 'lon', 'time'])  f = Dataset('HadCRUT.4.6.0.0.median.nc', 'r') print(f.variables.keys()) Tanom = f.variables['temperature_anomaly'][:] time = f.variables['time'][:] lon = f.variables['longitude'][:] lat = f.variables['latitude'][:] # print(f.variables['time']) f.close()  odict_keys(['latitude', 'longitude', 'time', 'temperature_anomaly', 'field_status'])  The size of Tanom is\nT.shape  (12, 36, 72)  Plot temperature 2D plot Let\u0026rsquo;s make a plot of T in 1850\nT1850 = T[0, :, :] + Tanom[0, :, :] # This is the monthly mean  imshow The simplest way to visualize a 2D variable is imshow. This function gives colors to each element of the array without considering grid information. It is fast and a good tool to check the variable.\nhelp(plt.imshow)  Help on function imshow in module matplotlib.pyplot: imshow(X, cmap=None, norm=None, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, origin=None, extent=None, shape=None, filternorm=1, filterrad=4.0, imlim=None, resample=None, url=None, *, data=None, **kwargs) Display an image, i.e. data on a 2D regular raster. Parameters ---------- X : array-like or PIL image The image data. Supported array shapes are: - (M, N): an image with scalar data. The data is visualized using a colormap. - (M, N, 3): an image with RGB values (float or uint8). - (M, N, 4): an image with RGBA values (float or uint8), i.e. including transparency. The first two dimensions (M, N) define the rows and columns of the image. The RGB(A) values should be in the range [0 .. 1] for floats or [0 .. 255] for integers. Out-of-range values will be clipped to these bounds. cmap : str or `~matplotlib.colors.Colormap`, optional A Colormap instance or registered colormap name. The colormap maps scalar data to colors. It is ignored for RGB(A) data. Defaults to :rc:`image.cmap`. aspect : {'equal', 'auto'} or float, optional Controls the aspect ratio of the axes. The aspect is of particular relevance for images since it may distort the image, i.e. pixel will not be square. This parameter is a shortcut for explicitly calling `.Axes.set_aspect`. See there for further details. - 'equal': Ensures an aspect ratio of 1. Pixels will be square (unless pixel sizes are explicitly made non-square in data coordinates using *extent*). - 'auto': The axes is kept fixed and the aspect is adjusted so that the data fit in the axes. In general, this will result in non-square pixels. If not given, use :rc:`image.aspect` (default: 'equal'). interpolation : str, optional The interpolation method used. If *None* :rc:`image.interpolation` is used, which defaults to 'nearest'. Supported values are 'none', 'nearest', 'bilinear', 'bicubic', 'spline16', 'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric', 'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos'. If *interpolation* is 'none', then no interpolation is performed on the Agg, ps and pdf backends. Other backends will fall back to 'nearest'. See :doc:`/gallery/images_contours_and_fields/interpolation_methods` for an overview of the supported interpolation methods. Some interpolation methods require an additional radius parameter, which can be set by *filterrad*. Additionally, the antigrain image resize filter is controlled by the parameter *filternorm*. norm : `~matplotlib.colors.Normalize`, optional If scalar data are used, the Normalize instance scales the data values to the canonical colormap range [0,1] for mapping to colors. By default, the data range is mapped to the colorbar range using linear scaling. This parameter is ignored for RGB(A) data. vmin, vmax : scalar, optional When using scalar data and no explicit *norm*, *vmin* and *vmax* define the data range that the colormap covers. By default, the colormap covers the complete value range of the supplied data. *vmin*, *vmax* are ignored if the *norm* parameter is used. alpha : scalar, optional The alpha blending value, between 0 (transparent) and 1 (opaque). This parameter is ignored for RGBA input data. origin : {'upper', 'lower'}, optional Place the [0,0] index of the array in the upper left or lower left corner of the axes. The convention 'upper' is typically used for matrices and images. If not given, :rc:`image.origin` is used, defaulting to 'upper'. Note that the vertical axes points upward for 'lower' but downward for 'upper'. extent : scalars (left, right, bottom, top), optional The bounding box in data coordinates that the image will fill. The image is stretched individually along x and y to fill the box. The default extent is determined by the following conditions. Pixels have unit size in data coordinates. Their centers are on integer coordinates, and their center coordinates range from 0 to columns-1 horizontally and from 0 to rows-1 vertically. Note that the direction of the vertical axis and thus the default values for top and bottom depend on *origin*: - For ``origin == 'upper'`` the default is ``(-0.5, numcols-0.5, numrows-0.5, -0.5)``. - For ``origin == 'lower'`` the default is ``(-0.5, numcols-0.5, -0.5, numrows-0.5)``. See the example :doc:`/tutorials/intermediate/imshow_extent` for a more detailed description. shape : scalars (columns, rows), optional, default: None For raw buffer images. filternorm : bool, optional, default: True A parameter for the antigrain image resize filter (see the antigrain documentation). If *filternorm* is set, the filter normalizes integer values and corrects the rounding errors. It doesn't do anything with the source floating point values, it corrects only integers according to the rule of 1.0 which means that any sum of pixel weights must be equal to 1.0. So, the filter function must produce a graph of the proper shape. filterrad : float \u0026gt; 0, optional, default: 4.0 The filter radius for filters that have a radius parameter, i.e. when interpolation is one of: 'sinc', 'lanczos' or 'blackman'. resample : bool, optional When *True*, use a full resampling method. When *False*, only resample when the output image is larger than the input image. url : str, optional Set the url of the created `.AxesImage`. See `.Artist.set_url`. Returns ------- image : `~matplotlib.image.AxesImage` Other Parameters ---------------- **kwargs : `~matplotlib.artist.Artist` properties These parameters are passed on to the constructor of the `.AxesImage` artist. See also -------- matshow : Plot a matrix or an array as an image. Notes ----- Unless *extent* is used, pixel centers will be located at integer coordinates. In other words: the origin will coincide with the center of pixel (0, 0). There are two common representations for RGB images with an alpha channel: - Straight (unassociated) alpha: R, G, and B channels represent the color of the pixel, disregarding its opacity. - Premultiplied (associated) alpha: R, G, and B channels represent the color of the pixel, adjusted for its opacity by multiplication. `~matplotlib.pyplot.imshow` expects RGB images adopting the straight (unassociated) alpha representation. .. note:: In addition to the above described arguments, this function can take a **data** keyword argument. If such a **data** argument is given, the following arguments are replaced by **data[\u0026lt;arg\u0026gt;]**: * All positional and all keyword arguments. Objects passed as **data** must support item access (``data[\u0026lt;arg\u0026gt;]``) and membership test (``\u0026lt;arg\u0026gt; in data``).  As shown above, you do not pass grid information to imshow.\nT1850  masked_array( data=[[--, --, --, ..., --, --, --], [--, --, --, ..., --, --, --], [--, --, --, ..., --, --, --], ..., [--, --, --, ..., --, --, --], [--, --, --, ..., --, --, --], [--, --, --, ..., --, --, --]], mask=[[ True, True, True, ..., True, True, True], [ True, True, True, ..., True, True, True], [ True, True, True, ..., True, True, True], ..., [ True, True, True, ..., True, True, True], [ True, True, True, ..., True, True, True], [ True, True, True, ..., True, True, True]], fill_value=1e+20)  f, ax = plt.subplots(1, 1, figsize=(12, 5)) c = ax.imshow(T1850) plt.colorbar(c)  \u0026lt;matplotlib.colorbar.Colorbar at 0x11bb3cb38\u0026gt;  imshow askes for a special argument if you want to modify the aspect ratio.\nf, ax = plt.subplots(1, 1, figsize=(15, 15)) c = ax.imshow(T1850, aspect='auto') plt.colorbar(c)  \u0026lt;matplotlib.colorbar.Colorbar at 0x112cad470\u0026gt;  You can twick the figure with different colormap, origin, interpolation, vmin and vmax.\nf, ax = plt.subplots(2, 2, figsize=(15, 8)) ax[0,0].imshow(T1850, origin='lower') ax[0,1].imshow(T1850, cmap='rainbow') # more at https://matplotlib.org/examples/color/colormaps_reference.html ax[1,0].imshow(T1850, interpolation='bilinear') ax[1,1].imshow(T1850, vmin=0, vmax=30)  \u0026lt;matplotlib.image.AxesImage at 0x11ba4fd30\u0026gt;  pcolormesh You can use pcolormesh in the same manner as imshow, but you can also pass the grid information.\nhelp(plt.pcolormesh)  Help on function pcolormesh in module matplotlib.pyplot: pcolormesh(*args, alpha=None, norm=None, cmap=None, vmin=None, vmax=None, shading='flat', antialiased=False, data=None, **kwargs) Create a pseudocolor plot with a non-regular rectangular grid. Call signature:: pcolor([X, Y,] C, **kwargs) *X* and *Y* can be used to specify the corners of the quadrilaterals. .. note:: ``pcolormesh()`` is similar to :func:`~Axes.pcolor`. It's much faster and preferred in most cases. For a detailed discussion on the differences see :ref:`Differences between pcolor() and pcolormesh() \u0026lt;differences-pcolor-pcolormesh\u0026gt;`. Parameters ---------- C : array_like A scalar 2-D array. The values will be color-mapped. X, Y : array_like, optional The coordinates of the quadrilateral corners. The quadrilateral for ``C[i,j]`` has corners at:: (X[i+1, j], Y[i+1, j]) (X[i+1, j+1], Y[i+1, j+1]) +--------+ | C[i,j] | +--------+ (X[i, j], Y[i, j]) (X[i, j+1], Y[i, j+1]), Note that the column index corresponds to the x-coordinate, and the row index corresponds to y. For details, see the :ref:`Notes \u0026lt;axes-pcolormesh-grid-orientation\u0026gt;` section below. The dimensions of *X* and *Y* should be one greater than those of *C*. Alternatively, *X*, *Y* and *C* may have equal dimensions, in which case the last row and column of *C* will be ignored. If *X* and/or *Y* are 1-D arrays or column vectors they will be expanded as needed into the appropriate 2-D arrays, making a rectangular grid. cmap : str or `~matplotlib.colors.Colormap`, optional A Colormap instance or registered colormap name. The colormap maps the *C* values to colors. Defaults to :rc:`image.cmap`. norm : `~matplotlib.colors.Normalize`, optional The Normalize instance scales the data values to the canonical colormap range [0, 1] for mapping to colors. By default, the data range is mapped to the colorbar range using linear scaling. vmin, vmax : scalar, optional, default: None The colorbar range. If *None*, suitable min/max values are automatically chosen by the `~.Normalize` instance (defaults to the respective min/max values of *C* in case of the default linear scaling). edgecolors : {'none', None, 'face', color, color sequence}, optional The color of the edges. Defaults to 'none'. Possible values: - 'none' or '': No edge. - *None*: :rc:`patch.edgecolor` will be used. Note that currently :rc:`patch.force_edgecolor` has to be True for this to work. - 'face': Use the adjacent face color. - An mpl color or sequence of colors will set the edge color. The singular form *edgecolor* works as an alias. alpha : scalar, optional, default: None The alpha blending value, between 0 (transparent) and 1 (opaque). shading : {'flat', 'gouraud'}, optional The fill style, Possible values: - 'flat': A solid color is used for each quad. The color of the quad (i, j), (i+1, j), (i, j+1), (i+1, j+1) is given by ``C[i,j]``. - 'gouraud': Each quad will be Gouraud shaded: The color of the corners (i', j') are given by ``C[i',j']``. The color values of the area in between is interpolated from the corner values. When Gouraud shading is used, *edgecolors* is ignored. snap : bool, optional, default: False Whether to snap the mesh to pixel boundaries. Returns ------- mesh : `matplotlib.collections.QuadMesh` Other Parameters ---------------- **kwargs Additionally, the following arguments are allowed. They are passed along to the `~matplotlib.collections.QuadMesh` constructor: agg_filter: a filter function, which takes a (m, n, 3) float array and a dpi value, and returns a (m, n, 3) array alpha: float or None animated: bool antialiased: bool or sequence of bools array: ndarray capstyle: {'butt', 'round', 'projecting'} clim: a length 2 sequence of floats; may be overridden in methods that have ``vmin`` and ``vmax`` kwargs. clip_box: `.Bbox` clip_on: bool clip_path: [(`~matplotlib.path.Path`, `.Transform`) | `.Patch` | None] cmap: colormap or registered colormap name color: matplotlib color arg or sequence of rgba tuples contains: callable edgecolor: color or sequence of colors facecolor: color or sequence of colors figure: `.Figure` gid: str hatch: {'/', '\\\\', '|', '-', '+', 'x', 'o', 'O', '.', '*'} in_layout: bool joinstyle: {'miter', 'round', 'bevel'} label: object linestyle: {'-', '--', '-.', ':', '', (offset, on-off-seq), ...} linewidth: float or sequence of floats norm: `.Normalize` offset_position: {'screen', 'data'} offsets: float or sequence of floats path_effects: `.AbstractPathEffect` picker: None or bool or float or callable pickradius: unknown rasterized: bool or None sketch_params: (scale: float, length: float, randomness: float) snap: bool or None transform: `.Transform` url: str urls: List[str] or None visible: bool zorder: float See Also -------- pcolor : An alternative implementation with slightly different features. For a detailed discussion on the differences see :ref:`Differences between pcolor() and pcolormesh() \u0026lt;differences-pcolor-pcolormesh\u0026gt;`. imshow : If *X* and *Y* are each equidistant, `~.Axes.imshow` can be a faster alternative. Notes ----- **Masked arrays** *C* may be a masked array. If ``C[i, j]`` is masked, the corresponding quadrilateral will be transparent. Masking of *X* and *Y* is not supported. Use `~.Axes.pcolor` if you need this functionality. .. _axes-pcolormesh-grid-orientation: **Grid orientation** The grid orientation follows the standard matrix convention: An array *C* with shape (nrows, ncolumns) is plotted with the column number as *X* and the row number as *Y*. .. _differences-pcolor-pcolormesh: **Differences between pcolor() and pcolormesh()** Both methods are used to create a pseudocolor plot of a 2-D array using quadrilaterals. The main difference lies in the created object and internal data handling: While `~.Axes.pcolor` returns a `.PolyCollection`, `~.Axes.pcolormesh` returns a `.QuadMesh`. The latter is more specialized for the given purpose and thus is faster. It should almost always be preferred. There is also a slight difference in the handling of masked arrays. Both `~.Axes.pcolor` and `~.Axes.pcolormesh` support masked arrays for *C*. However, only `~.Axes.pcolor` supports masked arrays for *X* and *Y*. The reason lies in the internal handling of the masked values. `~.Axes.pcolor` leaves out the respective polygons from the PolyCollection. `~.Axes.pcolormesh` sets the facecolor of the masked elements to transparent. You can see the difference when using edgecolors. While all edges are drawn irrespective of masking in a QuadMesh, the edge between two adjacent masked quadrilaterals in `~.Axes.pcolor` is not drawn as the corresponding polygons do not exist in the PolyCollection. Another difference is the support of Gouraud shading in `~.Axes.pcolormesh`, which is not available with `~.Axes.pcolor`. .. note:: In addition to the above described arguments, this function can take a **data** keyword argument. If such a **data** argument is given, the following arguments are replaced by **data[\u0026lt;arg\u0026gt;]**: * All positional and all keyword arguments. Objects passed as **data** must support item access (``data[\u0026lt;arg\u0026gt;]``) and membership test (``\u0026lt;arg\u0026gt; in data``).  # Use pcolormesh as imshow f, ax = plt.subplots(1, 1, figsize=(12, 5)) c = ax.pcolormesh(T1850) plt.colorbar(c)  \u0026lt;matplotlib.colorbar.Colorbar at 0x11fb12630\u0026gt;  f, ax = plt.subplots(1, 2, figsize=(12, 5)) ax[0].imshow(T1850[20:25, 20:30]) ax[0].grid('on') ax[1].pcolormesh(T1850[20:25, 20:30]) ax[1].grid('on')  /Users/hajsong/miniconda2/envs/py36/lib/python3.6/site-packages/matplotlib/cbook/__init__.py:424: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead. warn_deprecated(\u0026quot;2.2\u0026quot;, \u0026quot;Passing one of 'on', 'true', 'off', 'false' as a \u0026quot;  f, ax = plt.subplots(1, 1, figsize=(12, 5)) c = ax.pcolormesh(lon, lat, T1850) plt.colorbar(c)  \u0026lt;matplotlib.colorbar.Colorbar at 0x115b63c88\u0026gt;  f, ax = plt.subplots(2, 2, figsize=(15, 8)) # pcolor() can be very slow for large arrays. # In most cases you should use the similar but much faster pcolormesh instead ax[0,0].pcolor(lon, lat, T1850) ax[0,1].pcolormesh(lon, lat, T1850, edgecolors='black', linewidth=.1) ax[1,0].pcolormesh(lon, lat, T1850, cmap='rainbow') # more at https://matplotlib.org/examples/color/colormaps_reference.html ax[1,1].pcolormesh(lon, lat, T1850, vmin=-20, vmax=30)  \u0026lt;matplotlib.collections.QuadMesh at 0x115841ac8\u0026gt;  contour / contourf contour and contourf draw contour lines and filled contours, respectively. You can pass the grid information to these functions.\nT2018 = T[0, :, :] + Tanom[2016, :, :] # monthly mean T for 2018 January  f, ax = plt.subplots(1, 2, figsize=(16, 5)) c0 = ax[0].contour(lon, lat, T2018) plt.colorbar(c0, ax=ax[0]) c1 = ax[1].contourf(lon, lat, T2018) plt.colorbar(c1, ax=ax[1])  \u0026lt;matplotlib.colorbar.Colorbar at 0x115e1b438\u0026gt;  You can decide how many contours to show in two different ways: a number of contours or an actual range\nf, ax = plt.subplots(1, 2, figsize=(16, 5)) c0 = ax[0].contour(lon, lat, T2018, 20) ax[0].clabel(c0, inline=1, fontsize=10, fmt='%2.1f') c1 = ax[1].contourf(lon, lat, T2018, np.arange(0, 21, 5), extend='both') # ax[1].clabel(c1) plt.colorbar(c1, ax=ax[1])  \u0026lt;matplotlib.colorbar.Colorbar at 0x119b52ac8\u0026gt;  Quiver This is useful when you want to show the wind or ocean current.\nLet\u0026rsquo;s read the wind data.\nf = Dataset('uwnd.mon.mean.nc', 'r') print(f.variables.keys()) uwind = f.variables['uwnd'][:] # monthly data lon = f.variables['lon'][:] lat = f.variables['lat'][:] f.close() f = Dataset('vwnd.mon.mean.nc', 'r') print(f.variables.keys()) vwind = f.variables['vwnd'][:] # monthly data lon = f.variables['lon'][:] lat = f.variables['lat'][:] f.close()  odict_keys(['lat', 'lon', 'time', 'uwnd']) odict_keys(['lat', 'lon', 'time', 'vwnd'])  help(plt.quiver)  Help on function quiver in module matplotlib.pyplot: quiver(*args, data=None, **kw) Plot a 2-D field of arrows. Call signatures:: quiver(U, V, **kw) quiver(U, V, C, **kw) quiver(X, Y, U, V, **kw) quiver(X, Y, U, V, C, **kw) *U* and *V* are the arrow data, *X* and *Y* set the location of the arrows, and *C* sets the color of the arrows. These arguments may be 1-D or 2-D arrays or sequences. If *X* and *Y* are absent, they will be generated as a uniform grid. If *U* and *V* are 2-D arrays and *X* and *Y* are 1-D, and if ``len(X)`` and ``len(Y)`` match the column and row dimensions of *U*, then *X* and *Y* will be expanded with :func:`numpy.meshgrid`. The default settings auto-scales the length of the arrows to a reasonable size. To change this behavior see the *scale* and *scale_units* kwargs. The defaults give a slightly swept-back arrow; to make the head a triangle, make *headaxislength* the same as *headlength*. To make the arrow more pointed, reduce *headwidth* or increase *headlength* and *headaxislength*. To make the head smaller relative to the shaft, scale down all the head parameters. You will probably do best to leave minshaft alone. *linewidths* and *edgecolors* can be used to customize the arrow outlines. Parameters ---------- X : 1D or 2D array, sequence, optional The x coordinates of the arrow locations Y : 1D or 2D array, sequence, optional The y coordinates of the arrow locations U : 1D or 2D array or masked array, sequence The x components of the arrow vectors V : 1D or 2D array or masked array, sequence The y components of the arrow vectors C : 1D or 2D array, sequence, optional The arrow colors units : [ 'width' | 'height' | 'dots' | 'inches' | 'x' | 'y' | 'xy' ] The arrow dimensions (except for *length*) are measured in multiples of this unit. 'width' or 'height': the width or height of the axis 'dots' or 'inches': pixels or inches, based on the figure dpi 'x', 'y', or 'xy': respectively *X*, *Y*, or :math:`\\sqrt{X^2 + Y^2}` in data units The arrows scale differently depending on the units. For 'x' or 'y', the arrows get larger as one zooms in; for other units, the arrow size is independent of the zoom state. For 'width or 'height', the arrow size increases with the width and height of the axes, respectively, when the window is resized; for 'dots' or 'inches', resizing does not change the arrows. angles : [ 'uv' | 'xy' ], array, optional Method for determining the angle of the arrows. Default is 'uv'. 'uv': the arrow axis aspect ratio is 1 so that if *U*==*V* the orientation of the arrow on the plot is 45 degrees counter-clockwise from the horizontal axis (positive to the right). 'xy': arrows point from (x,y) to (x+u, y+v). Use this for plotting a gradient field, for example. Alternatively, arbitrary angles may be specified as an array of values in degrees, counter-clockwise from the horizontal axis. Note: inverting a data axis will correspondingly invert the arrows only with ``angles='xy'``. scale : None, float, optional Number of data units per arrow length unit, e.g., m/s per plot width; a smaller scale parameter makes the arrow longer. Default is *None*. If *None*, a simple autoscaling algorithm is used, based on the average vector length and the number of vectors. The arrow length unit is given by the *scale_units* parameter scale_units : [ 'width' | 'height' | 'dots' | 'inches' | 'x' | 'y' | 'xy' ], None, optional If the *scale* kwarg is *None*, the arrow length unit. Default is *None*. e.g. *scale_units* is 'inches', *scale* is 2.0, and ``(u,v) = (1,0)``, then the vector will be 0.5 inches long. If *scale_units* is 'width'/'height', then the vector will be half the width/height of the axes. If *scale_units* is 'x' then the vector will be 0.5 x-axis units. To plot vectors in the x-y plane, with u and v having the same units as x and y, use ``angles='xy', scale_units='xy', scale=1``. width : scalar, optional Shaft width in arrow units; default depends on choice of units, above, and number of vectors; a typical starting value is about 0.005 times the width of the plot. headwidth : scalar, optional Head width as multiple of shaft width, default is 3 headlength : scalar, optional Head length as multiple of shaft width, default is 5 headaxislength : scalar, optional Head length at shaft intersection, default is 4.5 minshaft : scalar, optional Length below which arrow scales, in units of head length. Do not set this to less than 1, or small arrows will look terrible! Default is 1 minlength : scalar, optional Minimum length as a multiple of shaft width; if an arrow length is less than this, plot a dot (hexagon) of this diameter instead. Default is 1. pivot : [ 'tail' | 'mid' | 'middle' | 'tip' ], optional The part of the arrow that is at the grid point; the arrow rotates about this point, hence the name *pivot*. color : [ color | color sequence ], optional This is a synonym for the :class:`~matplotlib.collections.PolyCollection` facecolor kwarg. If *C* has been set, *color* has no effect. Notes ----- Additional :class:`~matplotlib.collections.PolyCollection` keyword arguments: agg_filter: a filter function, which takes a (m, n, 3) float array and a dpi value, and returns a (m, n, 3) array alpha: float or None animated: bool antialiased: bool or sequence of bools array: ndarray capstyle: {'butt', 'round', 'projecting'} clim: a length 2 sequence of floats; may be overridden in methods that have ``vmin`` and ``vmax`` kwargs. clip_box: `.Bbox` clip_on: bool clip_path: [(`~matplotlib.path.Path`, `.Transform`) | `.Patch` | None] cmap: colormap or registered colormap name color: matplotlib color arg or sequence of rgba tuples contains: callable edgecolor: color or sequence of colors facecolor: color or sequence of colors figure: `.Figure` gid: str hatch: {'/', '\\\\', '|', '-', '+', 'x', 'o', 'O', '.', '*'} in_layout: bool joinstyle: {'miter', 'round', 'bevel'} label: object linestyle: {'-', '--', '-.', ':', '', (offset, on-off-seq), ...} linewidth: float or sequence of floats norm: `.Normalize` offset_position: {'screen', 'data'} offsets: float or sequence of floats path_effects: `.AbstractPathEffect` picker: None or bool or float or callable pickradius: unknown rasterized: bool or None sketch_params: (scale: float, length: float, randomness: float) snap: bool or None transform: `.Transform` url: str urls: List[str] or None visible: bool zorder: float See Also -------- quiverkey : Add a key to a quiver plot  f, ax = plt.subplots(1, 1, figsize=(16, 8)) q = ax.quiver(lon, lat, uwind[-1, :, :], vwind[-1, :, :]) # q = ax.quiver(lon, lat, uwind[-1,...], vwind[-1,...])  Although we have the plot with arrows, it is not easy to see their sizes and direction.\nIt seems that there needs some tunings.\nhelp(plt.quiverkey)  Help on function quiverkey in module matplotlib.pyplot: quiverkey(Q, X, Y, U, label, **kw) Add a key to a quiver plot. Call signature:: quiverkey(Q, X, Y, U, label, **kw) Arguments: *Q*: The Quiver instance returned by a call to quiver. *X*, *Y*: The location of the key; additional explanation follows. *U*: The length of the key *label*: A string with the length and units of the key Keyword arguments: *angle* = 0 The angle of the key arrow. Measured in degrees anti-clockwise from the x-axis. *coordinates* = [ 'axes' | 'figure' | 'data' | 'inches' ] Coordinate system and units for *X*, *Y*: 'axes' and 'figure' are normalized coordinate systems with 0,0 in the lower left and 1,1 in the upper right; 'data' are the axes data coordinates (used for the locations of the vectors in the quiver plot itself); 'inches' is position in the figure in inches, with 0,0 at the lower left corner. *color*: overrides face and edge colors from *Q*. *labelpos* = [ 'N' | 'S' | 'E' | 'W' ] Position the label above, below, to the right, to the left of the arrow, respectively. *labelsep*: Distance in inches between the arrow and the label. Default is 0.1 *labelcolor*: defaults to default :class:`~matplotlib.text.Text` color. *fontproperties*: A dictionary with keyword arguments accepted by the :class:`~matplotlib.font_manager.FontProperties` initializer: *family*, *style*, *variant*, *size*, *weight* Any additional keyword arguments are used to override vector properties taken from *Q*. The positioning of the key depends on *X*, *Y*, *coordinates*, and *labelpos*. If *labelpos* is 'N' or 'S', *X*, *Y* give the position of the middle of the key arrow. If *labelpos* is 'E', *X*, *Y* positions the head, and if *labelpos* is 'W', *X*, *Y* positions the tail; in either of these two cases, *X*, *Y* is somewhere in the middle of the arrow+label key object.  f, ax = plt.subplots(1, 1, figsize=(16, 8)) # Try to show arrows at every three points. intv = 3 q = ax.quiver(lon[::intv], lat[::intv], uwind[-1, ::intv, ::intv], vwind[-1, ::intv, ::intv]) qk = ax.quiverkey(q, 10, 95, 10, '10 m/s', labelpos='E', coordinates='data', color='r', labelcolor='r', fontproperties={'size': 15})  from mpl_toolkits.basemap import Basemap X, Y =np.meshgrid(lon, lat) plt.figure(figsize=(15,5)) m = Basemap(projection='robin',lon_0=0,resolution='c') m.drawcoastlines() m.drawparallels(np.arange(-90.,120.,30.)) m.drawmeridians(np.arange(0.,360.,60.)) m.quiver(X[::intv, ::intv], Y[::intv, ::intv], uwind[-1, ::intv, ::intv], vwind[-1, ::intv, ::intv], latlon=True)  "
},
{
	"uri": "https://hajsong.github.io/ATM4110/linux/diroperation/",
	"title": "Directory operation",
	"tags": ["cd", "mkdir"],
	"description": "",
	"content": " Filesystem structure Every Linux file is contained in a collection called a directory. Directories are like folders on Windows and Mac systems. Directories form a hierarchy, or tree: one directory may contain other directories, called subdirectories, which may themselves contain other files and subdirectories, and so on, into infinity. The topmost directory is called the root directory and is denoted by a slash (/).\nPath We refer to files and directories using a \u0026ldquo;names and slashes\u0026rdquo; syntax called a path. To find out the current path, try\n$ pwd  and you will get your current location in the filesystem.\nThere are two types of path. The first one is an absolute path. The absolute path starts from the root directory and has all the names of directories in the upper level. The second type is a relative path. The relative path does not start with the root directory or contain all the names of directories in the upper levels.\ncd [directory] To move your location in the shell environment, you can use the cd command:\n$ cd /one/two/three  This command line moves you from your working directory (or current location) to /one/two/three. This example uses the absolute path to go to the new working directory. From here, you can use the relative path to go to /one/two with the following command:\n$ cd ..  In the shell environment, \u0026quot;..\u0026quot; means the upper level. (\u0026quot;.\u0026quot; means the current level.) You can use \u0026quot;..\u0026quot; as many times as you want. For example, if you want to move to /one from /one/two/three, you can type:\n$ cd ../..  Please note that you can achieve the same result with the absolute path:\n$ cd /one  Each user has own home directories where users\u0026rsquo; personal files are often found. In general, the path of the home directory starts with /home. To find out the absolute path for your home directory, try:\n$ echo $HOME  Linux offers a command that brings you to your home directory from anywhere. All you can do is just type cd with no arguments. It also provides a simple way to write the absolute path of your home directory with a special character, ~. Check this out.\n$ echo ~  You will get the same result as above. This special character can be quite handy. Suppose you want to move to Documents/Public in your home directory from /one/two/three. Then you can just type:\n$ cd ~/Documents/Public  If another username follows ~, the shell expands this string to be the user\u0026rsquo;s home directory:\n$ cd ~smith $ pwd /home/smith  mkdir [options] directory mkdir creates one or more directories:\n$ mkdir dirname  rm -r dirname will delete the directory called dirname.  "
},
{
	"uri": "https://hajsong.github.io/ATM4110/linux/",
	"title": "Unix/Linux system",
	"tags": ["Unix", "Linux"],
	"description": "",
	"content": " Unix/Linux? Most computing/programming in both atmospheric and oceanic sciences happens on Unix/Linux operating system, instead of Windows. What are the advantages of using Unix/Linux? I do not have the exact answer for why, but there must be a reason for people preferring typing and executing programs instead of clicking on windows (although Linux also provides graphical user interfaces).\nThe computing/programming in the atmospheric sciences means you create/read/process/write atmospheric data. All these jobs involve the design of the workflow from you, and it is important to be powerful, efficient and flexible in doing those. Unix is particularly suited to working in such an environment and has many powerful (and flexible) commands that can help you.\nAlso, according to Biocomputing Bootcamp, \u0026ldquo;The real strength of learning Unix is that most of these commands can be combined in an almost unlimited fashion. So if you can learn just five Unix commands, you will be able to do a lot more than just five things. Our objective here is to learn a subset of Unix and to become a productive Unix user without knowing or using every program and feature.\u0026rdquo;\nI refered to Linux, pocket guide by Daniel J. Barrett in introducing Linux system.\nHistory (and family) of Unix A varied operating systems, including macOS, have branched out from Unix. Simplified history of Unix-like operating systems (Wikipedia).\nLinux is one of the operating system that stems from UNIX and naturally shares similar architecture and concepts. It is an open-source software!\nPrograming on Linux \u0026ldquo;A common feature of Unix-like systems, Linux includes traditional specific-purpose programming languages targeted at scripting, text processing and system configuration and management in general. Linux distributions support shell scripts, awk, sed and make. Many programs also have an embedded programming language to support configuring or programming themselves. For example, regular expressions are supported in programs like grep and locate, the traditional Unix MTA Sendmail contains its own Turing complete scripting system, and the advanced text editor GNU Emacs is built around a general purpose Lisp interpreter.\u0026rdquo; (From Wikipedia)\nFour major parts in Linux The kernel The low-level operation system, handling files, disks, networking and other necessities we take for granted.\nSupplied program Thousands of programs for file manipulation, text editing, mathematics, typesetting, audio, video, computer programming, website creation, encryption\u0026hellip; you name it.\nThe shell A user interface for typing commands, executing them, and displaying results. There are various shells in existence: the Bourne shell, Korn shell, C shell, and others. We will focus on bash, the Bourne Shell, which is often the default for user accounts. However, all these shells have similar basic functions.\nX A graphical system that provides windows, menus, icons, mouse support, and other familiar GUI elements. More complex graphical environments are built on X; the most popular are KDE and GNOME.\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/environment/",
	"title": "Computing Environment",
	"tags": ["python", "jupyter notebook", "anaconda"],
	"description": "",
	"content": " The main tools being used in this course is Python and Jupyter Notebook.\nWhy are we going to learn python in this course? The scope of this class is to read atmospheric and oceanic datasets, do spatial, temporal and spectral analysis, and present the data graphically. Python provides an environment for us to fulfill those tasks seamlessly without asking too much time and effort to pay. Also, learning Python may open up other possibilities in your future because it is very popular computer languages these days.\nWhy Jupyter Notebook? The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Here is an example.\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/linux/fileoperation/",
	"title": "File Operation",
	"tags": ["ls", "cp", "rm"],
	"description": "",
	"content": " Once we arrive the working directory, the next thing we want to do might be manipulating files: copying, renaming, deleting and so forth. This page introduces a few things that can be useful in handling files in a Linux system.\nIf you need a short guide for the command, try with --help option. The content on this page mostly comes from Linux pocket guide by Daniel J. Barrett.\n ls [options] [files] The ls command lists attributes of files and directories. You can list files in the current directory:\n$ ls  in a given directories:\n$ ls dir1 dir2 dir3  or individually:\n$ ls file1 file2 file3  The most important options are -a and -l. By default, ls hides files whose names begin with a dot. The option -a displays all files including those starting with .(dot). The -l option produces a long listing, for example:\n-rw-r--r-- 1 hajsong staff 3376 Sep 3 08:18 _index.md -rw-r--r-- 1 hajsong staff 1340 Sep 3 12:53 configuration.md -rw-r--r-- 1 hajsong staff 3301 Sep 3 13:05 fileoperation.md -rw-r--r-- 1 hajsong staff 2707 Sep 3 12:52 filesystem.md -rw-r--r-- 1 hajsong staff 1066 Sep 3 11:23 shell.md  that includes, from left to right: the file\u0026rsquo;s permissions, owner, group, size, last modification date and name. When using the -l option, the list is created in the alphabetical order of the file names. It is sometimes useful to find out the most recently modified file. In this case, you can change the order according to the modification times.\n$ ls -ltr  The result looks like:\n-rw-r--r-- 1 hajsong staff 3376 Sep 3 08:18 _index.md -rw-r--r-- 1 hajsong staff 1066 Sep 3 11:23 shell.md -rw-r--r-- 1 hajsong staff 2707 Sep 3 12:52 filesystem.md -rw-r--r-- 1 hajsong staff 1340 Sep 3 12:53 configuration.md -rw-r--r-- 1 hajsong staff 3787 Sep 3 13:08 fileoperation.md  Here, -t makes the order according to the modification time, and -r reverses the order so that the latest comes to the bottom of the list. You may already notice that you can combine options by just line them up.\ncp [options] [files] (file/dir) The cp command copies a file:\n$ cp file file2  Using the -R option, you can also recursively copy directories.\n$ cp -R dir1 dir2  will create dir2 which is the same as dir1.\nUseful options\n -f: Force the copy. If a destination file exists, overwrite it unconditionally. -i: Interactive mode. Ask before overwriting destination files.  ln [options] source target A link is a reference to another file, created by the ln command. There are two kinds of links. A symbolic link refers to another file by its path, much like a Windows \u0026ldquo;shortcut\u0026rdquo; or a Mac \u0026ldquo;alias\u0026rdquo;.\n$ ln -s myfile softlink  If you delete the original file, the now-dangling link will be invalid, pointing to a nonexistent file path. A hard link, on the other hand, is simply a second name for a physical file on disk. Deleting the original file does not invalidate the link.\nIf you leave the softlink blank, then you get the link with the same name.\n$ ln myfile hardlink  Symbolic link can cross disk partitions, since they are just references to file paths. Hard links cannot. Symbolic links can also point to directories, whereas hard links cannot.\nIt is easy to find out where a symbolic link points with either of these command.\n$ readlink softlink  or\n$ ls -l softlink  useful options\n -s: Make a symbolic link. The default is a hard link. -i: Interactive mode. Ask before overwriting destination files. -f: Force the link. If a destination file exists, overwrite it unconditionally.  mv [options] source target The mv command can rename a file:\n$ mv file1 file2  or move files and directories into a destination directory.\n$ mv file1 destination_directory  useful options\n -i: Interactive mode. Ask before overwriting destination files. -f: Force the move. If a destination file exists, overwrite it unconditionally.  rm [options] files/directories The rm command can delete files:\n$ rm file1 file2 file3  or recursively delete directories:\nrm -r dir1 dir2  useful options\n -i: Interactive mode. Ask before deleting each file. -f: Force the deletion, ignoring any errors or warnings. -r: recursively remove a directory and its contents. USE WITH CAUTION, especially if combined with the -f option.  Beware! Once you delete the files or directories with rm, it is impossible or very difficult to recover them. "
},
{
	"uri": "https://hajsong.github.io/ATM4110/python/",
	"title": "Python",
	"tags": ["python", "jupyter notebook"],
	"description": "",
	"content": "The material here is based on the Chapter 3-5 in \u0026ldquo;A Hands-On Introduction to Using Python in the Atmospheric and Oceanic Sciences\u0026rdquo; by Johnny Wei-Bing Lin.  Python, like any other programming language, has variables and all the standard control structures. We will go though Python’s basic data and control structures that support procedural programming. Then we will explore how to use arrays, followed by file input and output.\nA few list of changes in Python 3.x that differs from Python 2.x\n The print function syntax now looks like any other function, e.g., print(\u0026quot;Hello\u0026quot;). The division operator uses floating point division, even when both the numerator and denominator are integers. Using raise to raise an exception has a new syntax. Dictionary methods keys and values no longer return lists. Neither does range. To make lists out of the return values, use the list function. Dictionaries no longer have the has_key method. Test instead for key in dict (where key is the key of interest and dict is your dictionary object). Note that if a value in your dictionary is the same as key, the membership testing will not return True. Relative imports (i.e., importing a module in the current directory) require the use of . in front of the module name. The version of NumPy generally installed with Python 3.x has a function ndim that gives the number of dimensions of an array, rather than rank.  "
},
{
	"uri": "https://hajsong.github.io/ATM4110/linux/filehandling/",
	"title": "File Handling",
	"tags": ["cat", "grep"],
	"description": "",
	"content": " 1. File viewing In Linux, you are going to handle files with lots of different types, and want to see what\u0026rsquo;s in there. On this page, we will explore how to view the file contents if they are in text in the Linux system.\ncat [options] [files] The simplest viewer is cat, which just copies its files to standard output, concatenating them.\n$ cat filename  This command dump all the contents on the screen, so large files will likely scroll off screen. If this is the case, you may consider using less command.\nuseful options\n -n: Prepend line numbers to every line  less [options] [files] Use less to view text one page at a time (or one window or screenful at a time). It\u0026rsquo;s great for text files.\nWhile running less, type h for a help message, but here are a few keystroke being used often.\n   Keystroke Meaning     h, H View a help page.   spacebar, f Move forward one screenful.   Enter Move forward one line.   b Move backward one screenful   / Enter search model. n goes to the next match, while N goes to the previous match.   q quite less.    useful options\n N: Prepend line numbers to the output.  Other useful commands head and tail are also useful in viewing files. To find out how to use them, you can refer to the manual after calling it.\n$ man head or $ man tail  The manual of these command will be printed on the screen using less command. That means that you can move around between pages using the keystrokes in the table above.\n2. File Creation and Editing Creating files is easy and can be done in many different ways in Linux. Instead of printing out the output on the screen, you can create a file containing the output by redirecting it.\n$ echo save text in the file \u0026gt; output $ ls -l \u0026gt; listdir  You can also quickly create an empty file using touch command,\n$ touch newfile  If you want to create and edit a file, you can try text editors. Two major text editors are emacs and vim in Linux, and new files can be created with the following commands.\n$ emacs newfile or $ vim newfile  There is a steep learning curve for these editors, but once you get familiar with them, you can do so many things very efficiently. Throughout the course, you need to create many text files to analyze the atmospheric data, and these text editors may boost your productivity.\nI use vim daily basis. So, I will introduce it briefly here with a few examples (There are tons of material about these text editors online. Of course, you do not have to use them.)\nvim [options] [files] You can open up the tutorial of vim withe command below.\n$ vimtutor  To exit from vimtutor, do :q.\n vim operates in two modes, insert and normal. Insert mode is for entering text in the usual manner, while normal mode is for running commands like \u0026ldquo;delete a line\u0026rdquo; or copy/paste.\nHere are basic keystrokes in normal mode.\n   Keystroke Meaning     $ vim run editor in current terminal.   i enter insert mode.   esc exit insert mode back to normal mode   :q quit vim when there is no modification   :q! quit vim without saving modification   :wq quit vim by overwriting the file with modification   :w save modification (overwrite)   :w filename save as filename   u undo   ^R redo   l or right arrow move forward   h or left arrow move backward   k or up arrow move up   j or down arrow move down   w move to next word   b move to previous word   e move to the end of the current word   0 move to beginning of line   $ move to end of line   ^f move down 1 screen   ^b move up 1 screen   gg move to beginning of buffer   G move to end of buffer i   x delete next character   X delete previous character   dd delete current line   de delete all characters to the end of the current word   dw delete all characters before the beginning of the next word   de delete all characters from the beginning of the current word   d0 delete all characters from the beginning of the current line   d$ delete all characters to the end of the current line   yy copy current line   ye copy all characters to the end of the current word   yw copy all characters before the beginning of the next word   ye copy all characters from the beginning of the current word   y0 copy all characters from the beginning of the current line   y$ copy all characters to the end of the current line   p paste   r and character replace with the character   R replace mode   o enter insert mode at the one line below   O enter insert mode at the one line up   . repeat the previous action   : switch to command mode    If you are in the intert mode, editing the text is quite similar to other programs like MS words.\n "
},
{
	"uri": "https://hajsong.github.io/ATM4110/aodata/",
	"title": "Atmos. &amp; Ocean Data",
	"tags": ["tag1", "tag2"],
	"description": "",
	"content": " We will explore how to load the atmospheric and oceanic data and read variables for the analysis and visualization of the data.\nNetCDF (Network Common Data Form (NetCDF) Introduction NetCDF is a platform-independent binary file format that facilitates the storage and sharing of data along with its metadata. Versions of the tools needed to read and write the format are available on practically every operating system and in every major language used in the atmospheric and oceanic sciences.\nBefore discussing how to do netCDF i/o in Python, let\u0026rsquo;s briefly review the structure of netCDF. There are four general types of parameters in a netCDF file: global attributes, variables, variable attributes, and dimensions.\nGlobal attributes are usually strings that describe the file as a whole, e.g., a title, who created it, what standards it follows, etc. Variables are the entities that hold data. These include both the data-proper (e.g., temperature, meridional wind, etc.), the domain the data is defined on (delineated by the dimensions), and metadata about the data (e.g., units). Variable attributes store the metadata associated with a variable. Dimensions define a domain for the data-proper, but they also have values of their own (e.g., latitude values, longitude values, etc.), and thus you usually create variables for each dimension that are the same name as the dimension.\nA module for NetCDF files There are a few number of modules that deal with netcdf files in python. We are going to use the NetCDF4 module by unidata.\nFirst, let\u0026rsquo;s install the module using anaconda.\nconda install -c anaconda netcdf4  We will explore how to handle the netCDF file using the climatological SST data by Reynolds and Smith.\nReading NetCDF files In Python, we use the Dataset constructor in netCDF4 to load the netcdf file.\nfrom netCDF4 import Dataset f = Dataset('SST_Reyn_Smith.nc', 'r')  Then, check the structure of the file with the print statement\nIn [2]: print(f) \u0026lt;class 'netCDF4._netCDF4.Dataset'\u0026gt; root group (NETCDF3_CLASSIC data model, file format NETCDF3): dimensions(sizes): X(360), T(12), Y(180) variables(dimensions): float32 X(X), float32 T(T), float32 Y(Y), float32 sst(T,Y,X) groups:  This particular file does not have long description. But you may see a long list of information attached to the netcdf file.\nIn [2]: f = Dataset('ascat_20160728_000600_metopa_50709_eps_o_coa_2401_ovw.l2.nc','r') In [3]: print(f) \u0026lt;class 'netCDF4._netCDF4.Dataset'\u0026gt; root group (NETCDF3_CLASSIC data model, file format NETCDF3): title: MetOp-A ASCAT Level 2 Coastal Ocean Surface Wind Vector Product title_short_name: ASCATA-L2-Coastal Conventions: CF-1.4 institution: EUMETSAT/OSI SAF/KNMI source: MetOp-A ASCAT software_identification_level_1: 1000 instrument_calibration_version: 0 software_identification_wind: 2401 pixel_size_on_horizontal: 12.5 km service_type: eps processing_type: O contents: ovw granule_name: ascat_20160728_000600_metopa_50709_eps_o_coa_2401_ovw.l2.nc processing_level: L2 orbit_number: 50709 start_date: 2016-07-28 start_time: 00:06:00 stop_date: 2016-07-28 stop_time: 01:47:58 equator_crossing_longitude: 321.384 equator_crossing_date: 2016-07-28 equator_crossing_time: 00:03:41 rev_orbit_period: 6081.7 orbit_inclination: 98.7 history: N/A references: ASCAT Wind Product User Manual, http://www.osi-saf.org/, http://www.knmi.nl/scatterometer/ comment: Orbit period and inclination are constant values. All wind directions in oceanographic convention (0 deg. flowing North) creation_date: 2016-07-28 creation_time: 02:50:02 dimensions(sizes): NUMROWS(3264), NUMCELLS(82) variables(dimensions): int32 time(NUMROWS,NUMCELLS), int32 lat(NUMROWS,NUMCELLS), int32 lon(NUMROWS,NUMCELLS), int16 wvc_index(NUMROWS,NUMCELLS), int16 model_speed(NUMROWS,NUMCELLS), int16 model_dir(NUMROWS,NUMCELLS), int16 ice_prob(NUMROWS,NUMCELLS), int16 ice_age(NUMROWS,NUMCELLS), int32 wvc_quality_flag(NUMROWS,NUMCELLS), int16 wind_speed(NUMROWS,NUMCELLS), int16 wind_dir(NUMROWS,NUMCELLS), int16 bs_distance(NUMROWS,NUMCELLS) groups:  Again, variables in python are in fact objects. Since we loaded the netcdf as f, we can see all methods and attributes with dir(f).\nIn [9]: dir(f) Out[9]: ['__class__', '__delattr__', '__dir__', . . . 'variables', 'vltypes']  Among them, dimensions and variables are used the most in reading the data. As you can guess from the name of the method, dimensions shows the dimensions in the data.\nIn [13]: f.dimensions Out[13]: OrderedDict([('X', \u0026lt;class 'netCDF4._netCDF4.Dimension'\u0026gt;: name = 'X', size = 360), ('T', \u0026lt;class 'netCDF4._netCDF4.Dimension'\u0026gt;: name = 'T', size = 12), ('Y', \u0026lt;class 'netCDF4._netCDF4.Dimension'\u0026gt;: name = 'Y', size = 180)])  This means that variables have dimensions that are defined as X, Y and T.\nTo get the list of variables,\nIn [3]: f.variables.keys() Out[3]: odict_keys(['X', 'T', 'Y', 'sst'])  To get the details of the variable, for example, T,\nIn [5]: print(f.variables['T']) \u0026lt;class 'netCDF4._netCDF4.Variable'\u0026gt; float32 T(T) standard_name: time pointwidth: 1.0 calendar: 360 modulus: 12.0 modulo: 12.0 gridtype: 1 units: months since 1960-01-01 unlimited dimensions: current shape = (12,) filling on, default _FillValue of 9.969209968386869e+36 used  You get the list of information associated with this variable. Following the notation of object, we can access these information. For example, the unit of T can be obtained by\nIn [7]: f.variables['T'].units Out[7]: 'months since 1960-01-01'  The data can be obtained as the following.\nIn [10]: time = f.variables['T'][:] In [11]: time Out[11]: masked_array(data=[ 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5], mask=False, fill_value=1e+20, dtype=float32) In [12]: print(time) [ 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 10.5 11.5]  The variable, time is MaskedArray.\nAll datasets of real-world phenomena will have missing data: instruments will malfunction, people will make measurement errors, etc. Traditionally, missing data has been handled by assigning a value as the \u0026ldquo;missing value\u0026rdquo; and setting all elements of the dataset that are \u0026ldquo;bad\u0026rdquo; to that value. (Usually, the missing value is a value entirely out of the range of the expected values, e.g., -99999.)\nAs an object-oriented program, python thinks that variables are actually one type of objects carrying attributes and methods. In the atmospheric and oceanic sciences (AOS) applications, this means that data and metadata (e.g., grid type, missing values, etc.) can both be attached to the \u0026ldquo;variable.\u0026rdquo; Using this capability, we can define array-like variables: masked arrays. These array-like variables incorporate metadata attached to the arrays and define how that metadata can be used as part of analysis, visualization, etc.\nRecall that arrays are n-dimensional vectors or grids that hold numbers (or characters). Masked arrays, then, are arrays that also have a “mask” attributem which tells you which elements are bad, and masked variables are masked arrays that also give domain information and other metadata information.\nThe properties of MaskedArray type become clearer with sst variable. Let\u0026rsquo;s read it.\nIn [15]: sst = f.variables['sst'][:] In [16]: sst Out[16]: masked_array( data=[[[--, --, --, ..., --, --, --], [--, --, --, ..., --, --, --], [--, --, --, ..., --, --, --], ..., [-1.7999999523162842, -1.7999999523162842, -1.7999999523162842, ..., -1.7999999523162842, -1.7999999523162842, -1.7999999523162842], . . . mask=[[[ True, True, True, ..., True, True, True], [ True, True, True, ..., True, True, True], [ True, True, True, ..., True, True, True], ..., [False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False]], . . . [False, False, False, ..., False, False, False]]], fill_value=-999.9, dtype=float32)  As you can see, there are attributes attached to sst and they are data, mask, fill_value and dtype.\nThe mask is a boolean array whose elements are set to True if the value in the corresponding array is considered \u0026ldquo;bad\u0026rdquo;. Thus, in the masked array sst, the first row has mask values set to True, and when the data for the masked array is printed out for a human viewer, those elements display \u0026ldquo;\u0026ndash;\u0026rdquo; instead of a number.\nWe also note that the masked array sst has an attribute called fill_value that is set to -999.0. This is the value used to fill-in all the \u0026ldquo;bad\u0026rdquo; elements when we \u0026ldquo;deconstruct\u0026rdquo; the masked array. That is to say, when we convert a masked array to a normal NumPy array, we need to put something in for all the \u0026ldquo;bad\u0026rdquo; elements (i.e., where the mask is True): the value of fill_value is what we put in for the \u0026ldquo;bad\u0026rdquo; elements.\nFor masked arrays, operations using elements whose mask value is set to True will create results that also have a mask value set to True. For example,\nIn [24]: sst[0,10,10] Out[24]: masked In [25]: sst[0,20,10] Out[25]: -0.59 In [26]: sst[0,10,10] + sst[0,20,10] Out[26]: masked  Thus, the addition of a \u0026ldquo;good\u0026rdquo; value and a \u0026ldquo;bad\u0026rdquo; value yields a “bad” value. Product of these two values also results in a \u0026ldquo;bad\u0026rdquo; value.\nIn [27]: sst[0,10,10] * sst[0,20,10] Out[27]: masked  However, masked values are not considered in the statistical calculation. For example, if you want to compute the climatological mean sea surface temperature in January,\nIn [46]: print(sst[0,:,:].mean()) 13.551309957258193  In some cases, you can assign np.nan that represents \u0026ldquo;not a number\u0026rdquo; for \u0026ldquo;bad\u0026rdquo; values. Assigning a specific value for a masked array can be done easily with the method filled.\nIn [53]: sst.filled? Signature: sst.filled(fill_value=None) Docstring: Return a copy of self, with masked values filled with a given value. **However**, if there are no masked values to fill, self will be returned instead as an ndarray. Parameters ---------- fill_value : scalar, optional The value to use for invalid entries (None by default). If None, the `fill_value` attribute of the array is used instead. Returns ------- filled_array : ndarray A copy of ``self`` with invalid entries replaced by *fill_value* (be it the function argument or the attribute of ``self``), or ``self`` itself as an ndarray if there are no invalid entries to be replaced. Notes ----- The result is **not** a MaskedArray! . . . In [54]: jansst = sst[0,...] In [55]: jansst Out[55]: masked_array( data=[[--, --, --, ..., --, --, --], [--, --, --, ..., --, --, --], [--, --, --, ..., --, --, --], ..., [-1.7999999523162842, -1.7999999523162842, -1.7999999523162842, ..., -1.7999999523162842, -1.7999999523162842, -1.7999999523162842], [-1.7999999523162842, -1.7999999523162842, -1.7999999523162842, ..., -1.7999999523162842, -1.7999999523162842, -1.7999999523162842], [-1.7999999523162842, -1.7999999523162842, -1.7999999523162842, ..., -1.7999999523162842, -1.7999999523162842, -1.7999999523162842]], mask=[[ True, True, True, ..., True, True, True], [ True, True, True, ..., True, True, True], [ True, True, True, ..., True, True, True], ..., [False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False]], fill_value=-999.9, dtype=float32) In [56]: jansst.filled() # fill masked spaces with \u0026quot;fill_value\u0026quot; Out[56]: array([[-999.9, -999.9, -999.9, ..., -999.9, -999.9, -999.9], [-999.9, -999.9, -999.9, ..., -999.9, -999.9, -999.9], [-999.9, -999.9, -999.9, ..., -999.9, -999.9, -999.9], ..., [ -1.8, -1.8, -1.8, ..., -1.8, -1.8, -1.8], [ -1.8, -1.8, -1.8, ..., -1.8, -1.8, -1.8], [ -1.8, -1.8, -1.8, ..., -1.8, -1.8, -1.8]], dtype=float32) In [57]: jansst.filled(np.nan) # assign a specific value for the masked space Out[57]: array([[ nan, nan, nan, ..., nan, nan, nan], [ nan, nan, nan, ..., nan, nan, nan], [ nan, nan, nan, ..., nan, nan, nan], ..., [-1.8, -1.8, -1.8, ..., -1.8, -1.8, -1.8], [-1.8, -1.8, -1.8, ..., -1.8, -1.8, -1.8], [-1.8, -1.8, -1.8, ..., -1.8, -1.8, -1.8]], dtype=float32) In [58]: jansstfill = jansst.filled(np.nan) In [59]: jansstfill.mean() Out[59]: nan In [70]: np.nanmean(jansstfill) Out[70]: 13.55131  As you can see from this example, having np.nan as an element results in nan in the statistical calculation. Numpy provides functions for statistical calculations of arrays with np.nan, and np.nanmean is one of them.\nWhen you are done with reading the data, close the file with f.close().\nMasked array I think it will be useful to discuss more about the masked array. We saw that the variables from NetCDF files are in masked array, and it has advantages in processing and visualizing the data (we will see this).\nThen you may wonder whether we can create masked arrays. Yes, we can using Numpy module. The numpy.ma module is available to work with data arrays with masks.\nimport numpy as np import numpy.ma as ma a = np.array([[1,2,3],[4,5,6]]) b = ma.masked_array(data=[1,2,3], mask=[True, False, False], fill_value=-999)  In IPython,\nIn [9]: b Out[9]: masked_array(data=[--, 2, 3], mask=[ True, False, False], fill_value=-999)  When dealing with the real data set where we cannot specify individual values for the array, other methods may be more useful to create masked arrays. For example,\n   function description     masked_equal(x, value[, copy]) Mask an array where equal to a given value.   masked_greater(x, value[, copy]) Mask an array where greater than a given integer value.   masked_less(x, value[, copy]) Mask an array where less than a given value.   masked_invalid(a[, copy]) Mask an array where invalid values occur (NaNs or infs).   masked_values(x, value[, copy, …]) Mask using floating point equality.   masked_where(condition, a[, copy]) Mask an array where a condition is met.    Hierarchical Data Format (HDF) Data managed by NASA are usually in HDF type format (HDF4, HDF5, HDF EOS 5) Since I do not heavily use this data type, it may be better to quote what Dennis Shea (NCAR) says through https://climatedataguide.ucar.edu/climate-data-tools-and-analysis/hdf.\n\u0026ldquo;The Hierarchial Data Format is available in two versions: the original HDF4 and the more recent HDF5. Unfortunately, HDF4 and HDF5 interfaces and data models are completely incompatible. The HDF5 data model is more flexible and is a \u0026ldquo;a true hierarchical file structure, similar to the Unix file system.\u0026rdquo; HDF5 does have some new features that are appealing to climate research, such as, parallel I/O and variable compression. (Note: Our experience is that any compression level greater that \u0026lsquo;1\u0026rsquo; is not worth the additional time required for the increased compression.)\nThe HDF{4\u0026frasl;5}-EOS format extension defines three additional data types based on HDF objects: grid, point, and swath. These data types allow the file contents to be referenced to Earth coordinates, such as latitude and longitude, and to time. An irritating issue is that standard HDF library calls cannot readily access geolocation or time data or metadata. Users must use the HDF{4\u0026frasl;5}-EOS interfaces.The converse is also true. Certain information can only be accessed via standard HDF4 interfaces. Hence, both interfaces may be required to get at all the information on the file.\nThe netCDF user communities have numerous conventions for creating the contents of netCDF files, in particular, the commonly used COARDS and CF conventions. Unfortunately, the HDF communities do not seem to have any generally adopted conventions for HDF files. Perhaps, the variety of data sources, particularly satellites, inhibits the creation of common conventions?\u0026rdquo;\nReading HDF5 type file can be done using netCDF4 package. In the class, I will show this.\nGRIB Binary file "
},
{
	"uri": "https://hajsong.github.io/ATM4110/visual/",
	"title": "Visualization",
	"tags": ["visualization", "matplotlib"],
	"description": "",
	"content": " Visualizing the results is the key process of the atmospheric and oceanic data analysis. Since Python is an open-source programming language, there are more than one options for visualizing the result. Those include PyNGL by NCAR, Visualization Control System by UV-CDAT and Matplotlib. In the class, we will focus on Matplotlib.\nMatplotlib Matplotlib is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. Matplotlib can be used in Python scripts, the Python and IPython shells, the Jupyter notebook, web application servers, and four graphical user interface toolkits. The visualization work you can do with Matplotlib has a wide range of spectrum. To see examples, visit the gallery page.\nMatplotlib is the whole package, and most plotting tasks can be done with matplotlib.pyplot, a module in matplotlib.\nTo use this module, we can import it using the same command we used for numpy.\nimport matplotlib.pyplot as plt  Unless otherwise stated, you may assume in the examples in this chapter that the above import has been done prior to any matplotlib calls being run.\nParts of a Figure Figure The figure represents the whole space where plots are shown. A figure can have any number of axes where the actual drawing are happening.\nAxes This is a area where \u0026lsquo;a plot\u0026rsquo; is going to be drawn using the data. There can be more than one axes in a single figure. The Axes contains two (or three in the case of 3D) Axis objects.\nAxis These are the number-line-like objects. They take care of setting the graph limits and generating the ticks and ticklabels. There are 2 axis along each direction in 2D figures, but can be three for 3D figures.\nArtist Basically everything you can see on the figure is an artist (even the Figure, Axes, and Axis objects). This includes Text objects, Line2D objects, collection objects, Patch objects \u0026hellip; (you get the idea). When the figure is rendered, all of the artists are drawn to the canvas. Most Artists are tied to an Axes; such an Artist cannot be shared by multiple Axes, or moved from one to another.\nThe sample of matplotlib can clarify these concepts. Interactive mode When you make plots, you can choose to make them interactively, meaning deciding the next step after getting the intermediate results. Or, you can write down all the commands once and let matplotlib interprete them to the plot, which is non-interactive.\nTo turn on the interactive mode, you can use plt.ion(). To turn it off and come back to the non-interactive mode (which is the default), type plt.ioff().\nFor example,\nimport matplotlib.pyplot as plt plt.ion() plt.plot([1.6, 2.7])  Then we can keep adding more texts because the interactive mode is on.\nplt.title(\u0026quot;interactive test\u0026quot;) plt.xlabel(\u0026quot;index\u0026quot;)  and you will see the plot being updated after each line.\nTo go back to the non-interactive mode,\nplt.ioff() plt.plot([1.6, 2.7])  As you can see, nothing happends in contrast to the previous example. To have the figure, we need to say plt.show(). Now you see the plot, but your terminal command line is unresponsive; the show() command blocks the input of additional commands until you manually kill the plot window.\nWhat good is this\u0026ndash;being forced to use a blocking function? Suppose you need a script that plots the contents of a file to the screen. You want to look at that plot, and then end the script. Without some blocking command such as show(), the script would flash up the plot and then end immediately, leaving nothing on the screen.\nIn addition, non-interactive mode delays all drawing until show() is called; this is more efficient than redrawing the plot each time a line in the script adds a new feature.\nObviously, we cannot cover all the functions of Matplotlib in the class. Instead, we will explore basic plotting functions such as plot, imshow, contour and pcolormesh.\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/statistic/",
	"title": "Statistical analysis",
	"tags": ["statistics", "python"],
	"description": "",
	"content": "  Confidence intervals Linear Regression Correlation  This lecture is based on the Chapter 3 in Data analysis methods in Physical Oceanography by Thomson and Emery.\nSample distribution Fundamental to any form of data analysis is the realization that we are usually working with a limited set (or sample) of random events drawn from a much larger population. To describe the sample, we often use the concept of the sample mean. If the sample has $N$ data values, $x_1, x_2, \\cdots, x_N$, the sample mean can be expressed as\n$$ \\bar{x} = \\frac{1}{N} \\sum^N_{i=1} x_i. $$\nThe sample mean is an unbiased estimate of the true population mean, $\\mu$. An \u0026ldquo;unbiased\u0026rdquo; estimator means that it is equal to the expected value, $E[x]$ so that $E[x] = \\mu$. We will come back to this concept later.\nThe sample mean locates the center of mass of the data distribution such that\n$$ \\sum^N_{i=1}(x_i - \\bar{x}) = 0, $$\nthat is, the sample mean splits the data so that there is an equal weighting of negative and positive values.\nYou may give weight, $f_i$, on each sample. Then the weighted sample mean is defined as\n$$ \\bar{x} = \\frac{1}{N} \\sum^N_{i=1} f_i x_i. $$\nIt is clear that the sample mean is recovered with the weights all equal to 1 in the weighted sample mean.\nThe sample mean values give us the center of mass of a data distribution. How about the spread of the data? To determine it, we need a measure of the sample variability or sample standard deviation, $s\u0026rsquo;$, which is expressed in terms of the positive square root of the sample variance, the average of the square of the sample deviation.\n$$ s\u0026rsquo;^2 = \\frac{1}{N} \\sum^N_{i=1} (x_i - \\bar{x})^2. $$\nThis measure expresses the typical difference of a data value from the mean value of all the data points. In general, it differs from the true population variance, $\\sigma^2$, and the population standard deviation, $\\sigma$, indicating that $s\u0026rsquo;$ is biased. An unbiased estimator of the population variance, $s$, is obtained from\n$$ s^2 = \\frac{1}{(N-1)} \\sum^N_{i=1} (x_i - \\bar{x})^2. $$\nAgain, we will come back to this concept later.\nThe difference between the sample standard deviation and population standard deviation becomes significant when the sample size is small ($N\u0026lt;30$).\nOther statistical values of importance are the range, mode, and median of a data distribution. The range is another measure for the spread and represents the difference between two extreme points. The mode is the value that occurs the most, while the median is the value at the middle of the distribution.\nMoments and expected values To describe the distribution and the related probability, we often compute parameters called \u0026ldquo;moments\u0026rdquo;. The first two moments are already introduced: the population mean and standard deviation. In general, these two moments are not enough to completely describe the distribution, except the normal (Gaussian) distribution.\nWhen discussing moments, it is useful to introduce the concept of expected values. This concept is analogous to the notion of weighted functions. If we know the probability function, $P(x)$, for the event $x$, the expected value for a discrete PDF is\n$$ E[X] = \\sum^N_{i=1} x_iP(x_i) = \\mu, $$\nwhere $\\mu$ is the population mean introduced earlier. As you can notice, this has very similar form to the weighted average. The difference is that the weighted average consider a single set of experimental samples whereas $P(x)$ is the expected relative frequency for an infinite number of samples from repeated trials of the experiment.\nThe variance of the random variable $X$ is the expected value of $(X-\\mu)^2$, or\n$$ V[X] = E[(X-\\mu)^2] = \\sum^N_{i=1}(x_i-\\mu)^2P(x_i) = \\sigma^2. $$\nHere are some properties of expected values for random variables:\n For $c=constant$, $E[c] = c, V[c] = 0$. $E[cg(X)] = cE[g(X)], V[cg(X)] = c^2V[g(X)]$ $E[g_1(X) \\pm g_x(X) \\pm \\dots] = E[g_1(X)] \\pm E[g_1(X)] \\pm \\dots$ $V[g(X)] = E[(g(X) - \\mu)^2] = E[g(X)^2]-\\mu^2$ $E[g_1g_2] = E[g_1]E[g_2]$ $V[g_1\\pm g_2] = V[g_1] + V{g_2} \\pm 2C[g_1, g_2]$ (where $C[g_1,g_2] = E[g_1g_2] - E[g_1]E[g_2]$)  The covariance function, $C[g_1, g_2]$ is zero when $g_1$ and $g_2$ are independent random variables.\nUsing the properties above, we can get the first and second moments of $Y = a + bX$ as\n$$ E[Y] = E[a+bX] = a+bE[x] $$\nand\n$$ V[Y] = V[a+bX] = b^2V[x]. $$\nThe normal distribution Perhaps the most familiar and widely used probability density function is the normal (Gaussian) density function:\nThe standardized normal variable, $Z$ for the normal distribution gives the distance of points measured from the mean of the normal random variable in terms of the standard deviation of the normal random variable, $X$.\n$$ f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right) $$ The probability between in the interval $a$ and $b$ is given by the integral of $f(x)$.\n$$ P(a \\le X \\le b) = \\int^b_a \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)dx $$\nFor normal distribution, we can come up with the distribution for the normalized variable, $Z$,\n$$ Z = \\frac{X-\\mu}{\\sum} $$\nThis is called the standardized normal variable. It gives the distance of points measured from the mean of the normal random variable in terms of the standard deviation of the normal random variable, $X$.\nCentral limit theorem Please see the link, and jupyter notebook.\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/spatial/",
	"title": "Spatial analysis",
	"tags": ["spatial", "objective"],
	"description": "",
	"content": "  Objective analysis Empirical orthogonal functions Normal mode analysis Kalman filter  Optimal interpolation In the class, we ran the code that optimally interpolate the pseudo observations onto the regularly gridded space. The dataset can be downloaded from this link.\nAnd the jupyter notebook for this exercise is here.\nEmpirical orthogonal functions (EOFs) As an exercise, we will compute the EOFs of the Pacific SST following the code by John Wilkin (Rutgers Univ.).\nThe dataset can be downloaded from this link and this link.\nAnd get the python code for this exercise from here. The jupyter notebook file we did in the class is this.\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/temporal/",
	"title": "Temporal analysis",
	"tags": ["temporal", "python"],
	"description": "",
	"content": " Lag Correlation Spectral analysis  "
},
{
	"uri": "https://hajsong.github.io/ATM4110/homework/homework6/",
	"title": "Homework 6",
	"tags": ["confidence interval", "precipitation"],
	"description": "",
	"content": " A confidence interval of monthly mean precipitation In the class, we learned how to compute the 95% confidence interval for a population mean. Using this method, try to estimate the 95% confidence interval for the monthly mean precipitation.\nSince we do not know the population standard deviation of the monthly mean precipitation, we have to use the sample standard deviation. In this case, the confidence interval can be estimated using t-distribution.\n$$ \\bar{x} - t \\frac{s}{\\sqrt{N}} \u0026lt; \\mu \u0026lt;\\bar{x} + t \\frac{s}{\\sqrt{N}} $$\nwhere $t$ is a critical value determined from the $t_{n-1}$ distribution in such a way that there is area 0.95 (95%) between t and -t.\nThe value $n-1$ is called degrees of freedom , or df for short ($n$ is the size of the sample), or $\\nu$. It is a parameter of the t-curve and changes the shape of the t-curve, though usually not by much. You can use this table to find out an appropriate $t$ critical values for selected $1 - \\alpha$ and n-1.\nBy the way, the example we did in the lecture has 20 samplings so that the degrees of freedom is 19. From the table, the $t$ values for $1-\\alpha = 0.95$ is 2.093. So we used this value.\nYou do not have to turn this homework in, but you can get extra points up to 5 if you turn in by 11\u0026frasl;23 (Friday).\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/visual/exercise/",
	"title": "Exercise",
	"tags": ["cartopy", "Basemap"],
	"description": "",
	"content": " We learned how to make 2D plots, and touched a little bit of cartopy and Basemap. (I prepared example jupyter notebooks for cartopy and Basemap.)\nBased on these lessons, we will finalize python lectures with this exercise!\nPlotting exercise We will practice what we learned about plotting data on a 2D space.\nFirst, let\u0026rsquo;s get the data.\nimport numpy as np import numpy.ma as ma import matplotlib.pyplot as plt from mpl_toolkits.basemap import Basemap import cartopy.crs as ccrs %matplotlib inline  data = np.load('exercisedata.npz') LON = data['LON'] LAT = data['LAT'] u10 = data['u10'] # zonal velocity at 10m (m/s) v10 = data['v10'] # meridional velocity at 10m (m/s) T2m = data['T2'] # temperature at 2m (K) LH = data['LH'] # latent heat (W/m2) Psfc = data['Psfc'] # surface pressure (Pa) w = data['w'] # vertical velocity (m/s) date = data['date'] mask = data['mask'] # land mask mask = ma.masked_where(mask==1, mask) mask += 1  1. Plot surface pressure Using the imshow function\n2. Plot temperature at 2m Using the pcolormesh function\n3. Plot latent heat Using the contour function\n4. Plot wind and its speed 4-1 Using arrows with colors 4-2 Using arrows with the same size on the background of wind speed 5. Find the hurricane track (using either cartopy or Basemap) The solution can be found here\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/homework/homework5/",
	"title": "Homework 5",
	"tags": ["linear algebra", "file io"],
	"description": "",
	"content": " A close look at the Keeling Curve Accurately measuring CO$_2$ in the atmosphere requires lots of effort and support. It is unfortunate that there were years without financial support in the early period of this program and David Keeling couldn\u0026rsquo;t make measurements.\nThis is shown in the dataset! You can see that some of the entries of CO$_2$ concentration are $-99.99$. Considering that this dataset contains concentration values, the negative entry doesn\u0026rsquo;t make sense. So $-99.99$ is not the CO$_2$ concentration but tells us that no measurements were made in those times.\nNow, let\u0026rsquo;s try to use linear algebra to fill those gaps.\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/homework/homework4/",
	"title": "Homework 4",
	"tags": ["class"],
	"description": "",
	"content": " Create weather forecast Using weather data from KMA, write a code to produce weather outlook/statement that looks like the section, \u0026ldquo;Detailed Forecast\u0026rdquo; in NWS.\n Pick a region you want to make forecast. In addition to max/min temperature, please add a statement that compares it with the climatological values. Try to create your own class to do this job. Turn in the python file or jupyter notebook file by next Thursday.  Try to include everything in the class definition so that you can get the forecast statement with \u0026lt;Classname\u0026gt;.\u0026lt;printfunction\u0026gt;.\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/homework/homework3/",
	"title": "Homework 3",
	"tags": ["list", "tuple"],
	"description": "",
	"content": " Take street address of Yonsei University (50 Yonsei-ro, Seodaemun-gu, Seoul 03722, Republic of Korea) and create a dictionary myaddress. Create a variable full_address that is the concatenation of all the elements of the myaddress variable by placing commas and blank spaces as needed. Using iteration, print out the full address.  "
},
{
	"uri": "https://hajsong.github.io/ATM4110/homework/homework2/",
	"title": "Homework 2",
	"tags": ["vim", "homework"],
	"description": "",
	"content": "Give vim a try at least once to create/edit documents.\n Create a text file by $ ls -l \u0026gt; dirlist Add the location of the dir at the top row Delete last three rows. Copy the first row (you added in 2) and paste at the end of the row Save file  "
},
{
	"uri": "https://hajsong.github.io/ATM4110/homework/homework1/",
	"title": "Homework 1",
	"tags": ["linux"],
	"description": "",
	"content": " Setup the linux environment. Create a folder for this class at your home directory. Copy something Change its name Create a symbolic link  "
},
{
	"uri": "https://hajsong.github.io/ATM4110/homework/",
	"title": " Homework",
	"tags": ["tag1", "tag2"],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/final/",
	"title": "Final project",
	"tags": ["final", "eofs", "OI"],
	"description": "",
	"content": "Please see the jupyter notebook for the final project.\nYou need two datasets.\n Aerosol optical depth data : link A grid file you need for optimal interpolation : link  Please let me and TA know if you have questions. Due date is 12\u0026frasl;21. Good luck!\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/python/pythonbasic/",
	"title": "Basic Data and Control Structures",
	"tags": ["python", "data type"],
	"description": "",
	"content": " 1. Overview of basic variables and operators Unlike languages like Fortran, Python is dynamically typed, variables take on the type of whatever they are set to when they are assigned. Thus, a=5 makes the variable a an integer, but a=5.0 makes the variable a floating point number. Additionally, because assignment can happen anytime during the program, this means you can change the type of the variable without changing the variable name.\nThe built-in variable types include:\n integer and floating point strings booleans : True and False nonetype : None lists and tuples : variable v.s. fixed dictionaries : consists of keys and values  Python is case-sensitive, so \u0026ldquo;N\u0026rdquo; and \u0026ldquo;n\u0026rdquo; are different. 2. Integer and Float The easiest way to get the idea of integer and float is probably with an example. If we define variables as the following:\na = 3.5 b = -2.1 c = 3 d = 4  Then arithmetic operations below\na*b b+c a/c c/d  give us\n# a*b -7.3500000000000005 # b+c 0.8999999999999999 # a/c 1.1666666666666667 # c/d (in Python2) 0 # c/d (in Python3) 0.75  We did not specify the data type, but Python automatically decides what type a variable based on the value/operation. For example, c/d returns integer because c and d are integers. Python will generally make the output type the type that retains the most information, so a/c returns float.\nHere’s a question: Why is the answer to a*b not exactly -7.35? Remember that floating point numbers on any binary computer are, in general, not represented exactly. The default formatting setting for the print command, will sometimes print out enough of the portion after the decimal point to show that.\n3. Strings String variables are created by setting text in either paired single or double quotes. For example,\na = 'hello' b = \u0026quot;hello\u0026quot;  both work as long as they are consistently paired.\nSome \u0026ldquo;special\u0026rdquo; strings include:\n \\n: newline character \\t: tab character \\\\: backslash  \u0026gt;\u0026gt;\u0026gt; a=\u0026quot;Hello \\nHello\u0026quot; \u0026gt;\u0026gt;\u0026gt; print(a) Hello Hello \u0026gt;\u0026gt;\u0026gt; a=\u0026quot;Hello \\tHello\u0026quot; \u0026gt;\u0026gt;\u0026gt; print(a) Hello Hello \u0026gt;\u0026gt;\u0026gt; a=\u0026quot;Hello \\\\Hello\u0026quot; \u0026gt;\u0026gt;\u0026gt; print(a) Hello \\Hello  Python uses the addition operator to join strings together.\n\u0026gt;\u0026gt;\u0026gt; a=\u0026quot;Hello\u0026quot; \u0026gt;\u0026gt;\u0026gt; b=\u0026quot; world\u0026quot; \u0026gt;\u0026gt;\u0026gt; print(a+b+'!') Hello world! \u0026gt;\u0026gt;\u0026gt; a+b 'Hello world'  4. Booleans Boolean variables are variables that can have only one of two values: True and False. In some languages, the integer value zero is considered false and the integer value one is considered true, which was the case in older versions of Python. Although this still seems to work in recent versions of Python, using True and False reduces ambiguity.\nNote the capitalization matters. \u0026gt;\u0026gt;\u0026gt; a=true Traceback (most recent call last): File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; NameError: name 'true' is not defined \u0026gt;\u0026gt;\u0026gt; a=True  Try this in a Python interpreter:\na = True b = False print(a and b) print(a or b) print(4 \u0026gt; 5)  What did you get?\n5. NoneType A variable of NoneType can have only a single value, the value None (N has to be capitalized). Try this in a Python interpreter:\na = None print(a is None) print(a == 4)  The first print statement will return True, while the second print statement will return False. The is operator compares \u0026ldquo;equality\u0026rdquo; not in the sense of value but in the sense of memory location. Although \u0026ldquo;a == None\u0026rdquo; also works, the better syntax for comparing to None is \u0026ldquo;a is None\u0026rdquo;.\nThis NoneType variables can be useful to safely initialize a parameter. After initialize a parameter with None, you need to assign a value before doing an operation. Otherwise, Python will give an error. This is a simple way to make sure that the variable is set to a real value.\n6. Lists and tuples Lists are ordered sequences. The items in the list do not have to be of the same type. You can define a list with both numbers and strings, and even another list.\nTo define a list, you use square brackets and commas.\na = [2, 3.2, 'hello', [-1.2, 'there', 5.5]]  To access elements, you use addresses that starts with zero. For example, the first element of a is a[0], the second is a[1]. If the element of the list is also a list, you can access the element with, for example, a[3][1]. In Python, list elements can also be addressed starting from the end; thus, a[-1] is the last element in list a, a[-2] is the next to last element, etc.\n\u0026gt;\u0026gt;\u0026gt; a[3][1] 'there' \u0026gt;\u0026gt;\u0026gt; a[-1] [-1.2, 'there', 5.5] \u0026gt;\u0026gt;\u0026gt; a[-2] 'hello'  You can create new lists by slicing an existing list.\nThe lower limit of the range is inclusive, and the upper limit of the range is exclusive.\n \u0026gt;\u0026gt;\u0026gt; a[0:3] [2, 3.2, 'hello'] \u0026gt;\u0026gt;\u0026gt; a[1:3] [3.2, 'hello'] \u0026gt;\u0026gt;\u0026gt; a[2:3] ['hello'] \u0026gt;\u0026gt;\u0026gt; a[3:3] []  The length of a list can be obtained using the len function.\n\u0026gt;\u0026gt;\u0026gt; len(a) 4 \u0026gt;\u0026gt;\u0026gt; len(a[0]) Traceback (most recent call last): File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; TypeError: object of type 'int' has no len() \u0026gt;\u0026gt;\u0026gt; len(a[3]) 3  The element can be replaced with other types of item without any issues.\n\u0026gt;\u0026gt;\u0026gt; a[2] = 0.0 \u0026gt;\u0026gt;\u0026gt; a [2, 3.2, 0.0, [-1.2, 'there', 5.5]]  Python allows you to modify the list by providing build-in functions. When a = [2, 3.2, 'hello', [-1.2, 'there', 5.5]],\n\u0026gt;\u0026gt;\u0026gt; a.insert(2,'everyone') \u0026gt;\u0026gt;\u0026gt; print(a) [2, 3.2, 'everyone', 'hello', [-1.2, 'there', 5.5]] \u0026gt;\u0026gt;\u0026gt; a.remove(2) \u0026gt;\u0026gt;\u0026gt; print(a) [3.2, 'everyone', 'hello', [-1.2, 'there', 5.5]] \u0026gt;\u0026gt;\u0026gt; a.append(4.5) \u0026gt;\u0026gt;\u0026gt; print(a) [3.2, 'everyone', 'hello', [-1.2, 'there', 5.5], 4.5]  Tuples are nearly identical to lists with the exception that tuples cannot be changed! To define tuples, you use parenthesis instead of square brackets.\n\u0026gt;\u0026gt;\u0026gt; b = (3.2, 'hello') \u0026gt;\u0026gt;\u0026gt; b[0] 3.2 \u0026gt;\u0026gt;\u0026gt; b[0]=1 Traceback (most recent call last): File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; TypeError: 'tuple' object does not support item assignment  You can, to an extent, treat strings as lists. Thus, if a = \u0026ldquo;hello\u0026rdquo;, then a[1:3] will return the substring \u0026ldquo;el\u0026rdquo;.  If the list contains lots of elements, you can break the list after the completion of an element and continue the list on the next line. Or you can put a backslash (\u0026rdquo;\\\u0026ldquo;) at the end of a line  7. Dictionaries Dictionaries are unordered lists whose elements are referenced by keys, not by position. Keys refer to Values that can be anything.\nWhen defining a dictionary, you use curly braces (\u0026ldquo;{}\u0026rdquo;). The elements of a dictionary are \u0026ldquo;Key:Value\u0026rdquo; pairs, separated by a colon. For example,\na = {'a':2, 'b':3.2, 'c':[-1.2, 'there', 5.5]}  It is similar to lists to access the elements, except you use the keys.\n\u0026gt;\u0026gt;\u0026gt; a['a'] 2 \u0026gt;\u0026gt;\u0026gt; a['c'] [-1.2, 'there', 5.5]  There are a few built-in functions for dictionaries.\n a.keys() : show all the keys a.values() : show all the values  "
},
{
	"uri": "https://hajsong.github.io/ATM4110/environment/python/",
	"title": "Python",
	"tags": ["python"],
	"description": "",
	"content": " I refer to Unidata online python training page for this page.  I recommend you to visit Unidata Online Python Training page. The main program language we will use in this course to handle atmospheric data is python. Before getting into \u0026ldquo;What is Python?\u0026rdquo;, here is one of the statements that shows why we want to learn it\n  I have used a combination of Perl, Fortran, NCL, Matlab, R and others for routine research, but found out this general- purpose language, Python, can handle almost all in an efficient way from requesting data from remote online sites to statistics, and graphics.  What Is Python?  ## What is Python? --- #### Python is a “batteries included” computer programming language. More concretely, Python is a programming language that, in contrast to other programming languages such as C, Fortran, or Java, allows users to more readily focus and solve domain problems instead of dealing with the complexity of how a computer operates. Python achieves this goal by having the following attributes: --- #### Python is a **high-level** language. It abstracts underlying computer-related technical details. For example, Python does not make its users think too much about computer memory management or proper declaration of variables and uses safe assumptions about what the programmer is trying to convey. In addition, a high-level language can be expressed in a manner closer to English prose or mathematical equations. --- #### Python is a **general-purpose** language. It can be used for all problems that a computer is capable of rather than specializing in a specific area such as statistical analysis. For example, Python can be used for both artificial intelligence and statistical analysis. Python can be used for a variety of heterogeneous tasks within a given work-flow. --- #### Python is an **interpreted** language. Evaluation of code to obtain results can happen immediately rather than having to go through a time-consuming, compile and run cycle, which thereby speeds up the thinking and experimentation processes. IPython is an interactive form of the Python language also invented by Fernando Pérez. These environments excel for rapid-prototype of code or quick and simple experimentation with new ideas. --- #### Python has a strong tools for solving problems. A standard library and numerous third-party libraries (e.g. numpy, matplotlib,...) yield a vast array of existing codebases and examples for solving problems. --- #### Python has many, many users It allows users to quickly find solutions and example code to problems with the help of Google and Stackoverflow.       function initSlides() { Reveal.initialize({ embedded : true, controls : false, center: true ,\thistory: false , progress: false , transition: \"fade\", dependencies: [ { src: '\\/ATM4110\\/revealjs\\/lib\\/js\\/classList.js\"', condition: function() { return !document.body.classList; } }, { src: '\\/ATM4110\\/revealjs\\/plugin\\/markdown\\/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } }, { src: '\\/ATM4110\\/revealjs\\/plugin\\/markdown\\/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } }, { src: '\\/ATM4110\\/revealjs\\/plugin\\/highlight\\/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }, { src: '\\/ATM4110\\/revealjs\\/plugin\\/zoom-js\\/zoom.js', async: true, condition: function() { return !!document.body.classList; } }, { src: '\\/ATM4110\\/revealjs\\/plugin\\/notes\\/notes.js', async: true, condition: function() { return !!document.body.classList; } } ] }); }   See it fullscreen var toto = document.getElementById('slideContent').innerHTML document.getElementById('slideFrame').contentWindow.document.write(document.getElementById('slideContent').innerHTML); document.getElementById('slideContent').remove(); document.addEventListener(\"DOMContentLoaded\",function(){ setTimeout(function () { document.getElementById('slideFrame').contentWindow.initSlides() ; }, 2000); }); function slideFullScreen() { document.open(); document.write(toto); document.close(); initSlides() }  These features, perhaps, come with a minor cost of reduced language performance, but this is a trade-off the vast majority of users are willing to make in order to gain all the advantages Python has to offer.\nwhat you can do with Python? Python is not just for atmospheric sciences. It has a wide area of application, and earth science is one of them. Largely, you may categorize applications into:\n Web development Data science  1. Web development Python can be used to create the webpage. We all know that webpage is basically html files (not Python). Although you can edit html files for the webpage, you can also use python to create html files for you. This is what I did to create the ATM2106 class webpage.\nSome sites wait for the input from the users and process the job before delivering the results back to users (Like Amazon). Python can play an important role in these dynamic websites. For example, one of my friends build the website called Trevii which helps you organize the trip after gathering informations online. The backbone of this website is also python!\n2. Data science In some sense, the purpose of using Python in this course is to do data science. Python is efficient when handling a large dataset. It does not necessarily faster than other programming languages like Fortran or C, as mentioned above. This is because Python has to figure out the data type while users specify it for Fortran or C. If you tell Python the data type, then it can process the data with much higher speed (approaching the speed of Fortran or C).\nHere, Data science includes machine learning! Here is an example from Towards Data Science.\nThe goal of this machine learning is to find out how to combine three numbers we provide. The first task is to generate training set.\nfrom random import randint TRAIN_SET_LIMIT = 1000 TRAIN_SET_COUNT = 100 TRAIN_INPUT = list() TRAIN_OUTPUT = list() for i in range(TRAIN_SET_COUNT): a = randint(0, TRAIN_SET_LIMIT) b = randint(0, TRAIN_SET_LIMIT) c = randint(0, TRAIN_SET_LIMIT) op = a + (2*b) + (3*c) TRAIN_INPUT.append([a, b, c]) TRAIN_OUTPUT.append(op)  The training set consists of 100 sets of three numbers, a, b, and c, and op = a + 2*b + 3*c. You can adjust the size of the training set by modifying TRAIN_SET_COUNT.\nNow, we will train the machine with this dataset. The package scikit-learn allows us to do machine learning easily.\nfrom sklearn.linear_model import LinearRegression predictor = LinearRegression() predictor.fit(X=TRAIN_INPUT, y=TRAIN_OUTPUT)  The machine learning is done, and predictor will compute op with three inputs.\nX_TEST = [[10, 20, 30]] outcome = predictor.predict(X=X_TEST) coefficients = predictor.coef_ print('Outcome : {}\\nCoefficients : {}'.format(outcome, coefficients))  We see that the coefficients from machine learning are exactly same as the one used in the training set. There are online courses from Stanford and Caltech if you are interested in learning it more.\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/python/python_more/",
	"title": "Functions, if statement and loops",
	"tags": ["do", "if", "def"],
	"description": "",
	"content": " 1. Functions Functions in Python, in theory, work both like functions and subroutines in Fortran, in that (1) input comes via arguments and (2) output occurs through: a return variable (like Fortran functions) and/or arguments (like Fortran subroutines). In practice, functions in Python are written to act like Fortran functions, with a single output returned. (The return value is specified by the return statement.) If you want multiple returns, it’s easier to put them into a list or use objects.\nFunction definitions begin with a def statement, followed by the name of the function and the argument list in parenthesis. At the end of this line comes colon. The contents of the function are written with indents (usually 4 spaces). When there is no indentation, Python assumes that the definition of the function is finished.\nFor example, the function to compute the area of the circle can be written as\ndef area(radius): area = 3.14 * (radius**2) return area  If you define this function without indentation, Python gives you an error as this.\n\u0026gt;\u0026gt;\u0026gt; def area(radius): ... area = 3.14 * (radius**2) File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 2 area = 3.14*(radius**2) ^ IndentationError: expected an indented block  Once you define the function, you can use it with the syntax in the definition.\n\u0026gt;\u0026gt;\u0026gt; a = area(3) \u0026gt;\u0026gt;\u0026gt; print(a) 28.26  Python accepts both positional and keyword arguments in the argument list of a function. Positional arguments are usually for required input while keyword arguments are usually for optional input. Typically, keyword arguments are set to some default value. If you do not want to have a default value set for the keyword, a safe practice is to just set the keyword to None.\nWe may tweak the previous area function by placing a keyword argument.\ndef area(radius, pi=None): area = pi * (radius**2) return area  What would you expect to see with a = area(3)? How about a = area(3, pi=3.14)?\nA list and dictionary variable can be useful when passing positional and keyword arguments.\nargs = [3,] kwds = {'pi':3.14} a = area(*args, **kwds)  As you can see above, a list args and kwds can be passed to the function area. This is particularly useful when the function needs many positional and keyword arguments.\nThere are some rules for passing in function arguments by lists and dictionaries:\n In the function call, put an asterisk (*) before the list that contains the positional arguments and put two asterisks (**) before the dictionary that contains the keyword arguments. The list of positional arguments is a list where each element in the list is a positional argument to be passed in, and the list is ordered in the same order as the positional arguments. The dictionary of keyword arguments uses string keys corresponding to the name of the keyword and the value of the key:value pairs as the value set to the keyword parameter.  2. Logical constructs You may be already familiar with logical constructs. In Python, the syntax for if-statements is\nif \u0026lt;condition\u0026gt;:  followed by the block of code to execute if  is true. There is no need for an \u0026ldquo;endif\u0026rdquo; line because indentation defines the contents of the if block. a = 3 if a == 3: print('I am a ', a) elif a == 2: print('I am a 2') else: print('I am not a 3 or 2')  Don’t forget the colon at the end of if, elif, and else statements 3. Looping The loop is also popular part of the programming. In Python, the loop begins with for.\nfor \u0026lt;index\u0026gt; in \u0026lt;list\u0026gt;:  Do not forget the colon at the end of the syntax.\nAs the if statement, the contents of the loop is defined with indentation. That means that the loop does not require the line with enddo or something like that.\nThe for loop is little different compared to the Fortran do loops. In Fortran, you specify a beginning value and an ending value (often 1 and an integer n) for an index, and the loop runs through all integers from that beginning value to that ending value, setting the index to that value. In Python, the loop index runs through a list of items, and the index is assigned to each item in that list, one after the other, until the list of items is exhausted. For example,\nfor i in [2, -3.3, 'hello', 1, -12]: print(i)  prints out\n2 -3.3 hello 1 -12  As mentioned in the previous page, list variables can have any variable types as elements.\nIf the iteration through numbers is desirable like Fortran, you can use a function range.\nfor i in range(5): print(i)  In Python2, range creates a list. But in Python3, it creates a range type variable.\n\u0026gt;\u0026gt;\u0026gt; a = range(3) \u0026gt;\u0026gt;\u0026gt; a range(0, 3) \u0026gt;\u0026gt;\u0026gt; list(a) [0, 1, 2]  The advantage of the range type in Python3 over the list type in Python2 is the reduced usage of the memory. In Python3, you do not need to secure memories for, for example, range(100000000).\nThe range function takes the form of range(stop) or range(start, stop[, step]).  Another useful function is enumerate. Here is an example.\na = [2, -3.3, 'hello', 1, -12] for i, v in enumerate(a): print(i, ': ', v)  results in\n0 : 2 1 : -3.3 2 : hello 3 : 1 4 : -12  You may figure out how enumerate works already. While iterating the list, enumerate assigns the index and the value to i and v, respectively.\nThe following block of the code does the same thing as above.\na = [2, -3.3, 'hello', 1, -12] for i in range(len(a)): print(i, ': ', a[i])  Python also has a while loop. It\u0026rsquo;s like any other while loop and begins with the syntax:\nwhile \u0026lt;condition\u0026gt;:  The code block (indented) that follows the while line is executed while  evaluates as True.\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/environment/jupyter/",
	"title": "Jupyter",
	"tags": ["jupyter notebook"],
	"description": "",
	"content": "The Jupyter Notebook supports over 40 different programming languages, and Python is just one of them. That means that once you know how to use the Jupyter Notebook, you can use it for other languages.\nThe Jupyter Notebook is making one of the most significant advances in the scientific computing. Here is what Nature says about the Jupyter Notebook in 2014\n  The free IPython notebook makes data analysis easier to record, understand and reproduce.  Here are a few examples of IPython Notebooks for science:\n LIGO Gravitational Wave Data Satellite Imagery Analysis 12 Steps to Navier-Stokes Computer Vision Machine Learning  "
},
{
	"uri": "https://hajsong.github.io/ATM4110/python/module/",
	"title": "Module",
	"tags": ["module"],
	"description": "",
	"content": "When you write a script, the moment may come when you think there must be functions that can do what you want to do. Python calls \u0026ldquo;modules\u0026rdquo;, and \u0026ldquo;packages\u0026rdquo; which is the collection of modules to assist users to do their job easily and quickly. (They are used interchangeably from time to time.) Unlike compiled languages like Fortran, these modules are not collections of object files but rather regular Python source code files. A module is a single source code file and a package is a directory containing source code files (and possibly subdirectories of source code files).\nTo use a module, users can call it with import command.\nimport \u0026lt;module name\u0026gt;  For example, you can call NumPy module for the computation regarding arrays.\n\u0026gt;\u0026gt;\u0026gt; import numpy \u0026gt;\u0026gt;\u0026gt; dir() ['__annotations__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__', 'numpy']  or in IPython,\nIn [1]: import numpy In [2]: whos Variable Type Data/Info ------------------------------ numpy module \u0026lt;module 'numpy' from '/Us\u0026lt;...\u0026gt;kages/numpy/__init__.py'\u0026gt;  To use functions in the NumPy module, you can first write the module name, followed by dot and the function name. For example,\na = numpy.sin(4)  assign sin(4) to a.\nCalling \u0026lt;module name\u0026gt; with import is essentially the same as running the python file \u0026lt;module name\u0026gt;.py. As an example, let\u0026rsquo;s suppose that ctof.py has\nTinC = int(input(\u0026quot;Enter a temperature in Celsius: \u0026quot;)) TinF = 9.0/5.0 * TinC + 32 print(\u0026quot;Temperature:\u0026quot;, TinC, \u0026quot;degC = \u0026quot;, TinF, \u0026quot;degF\u0026quot;)  In Python, we can run this script with the command of exec(open('ctof.py').read()).\nNow, let\u0026rsquo;s try\n\u0026gt;\u0026gt;\u0026gt; import ctof  What do you get?\nFor import numpy, however, Python loads many functions that NumPy has because it is technically a package of many files, not a module of a single file. If all the module file does is define functions, variables, etc., then nothing will be output. But you have access to everything that is defined by typing the module name, a period, then the name of the module function, variable, etc. you want (hence, numpy.sin, etc.). Just as in a regular Python session you have access to all the variables, functions, etc. you define in that regular session, with an imported module, all the variables, functions, etc. that the module created and used are also sitting inside the module\u0026rsquo;s namespace, ready for you to access, using the syntax just mentioned.\nSubmodules (which are subdirectories inside the package directory) are also specified with the periods. For instance, NumPy has a submodule called ma, which in turn has special functions defined in it. The submodule then is referred to as numpy.ma and the array function in the submodule as numpy.ma.array.\nWhen importing modules, shorter name can be assigned. For example,\nimport numpy as np  Once you assign the shorter name, you can call the function with it, e.g. np.sin.\nIf you are interested only one function in the module, you can call it as the following.\nfrom numpy import sin  Finally, remember, modules can contain data in addition to functions. The syntax to refer to those module data variables is exactly the same as for functions. Thus, numpy.pi gives the value of the mathematical constant.\nYou can create your own module and it will be explained later.\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/environment/setup/",
	"title": "Set up",
	"tags": ["tag1", "tag2"],
	"description": "",
	"content": "My recommendation of working environment is mobaxterm and python powered by anaconda. I wrote the Jupyter Notebook about how to install Python and packages here\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/python/object/",
	"title": "Introduction to Object",
	"tags": ["object", "class"],
	"description": "",
	"content": " Python is an object oriented programming language. In fact, almost everything in Python is an object. Then what is an object?\nAn object is a variable that has attached to it both data (attributes) and functions designed to act on that data (methods). So what does this mean?\nThe key idea of objects is that variables shouldn\u0026rsquo;t be thought of as having only values (and type), but rather they should be thought of entities that can have any number of other things \u0026ldquo;attached\u0026rdquo; to them. If the attached thing is a piece of data, it\u0026rsquo;s called an attribute of the object variable. If the attached thing is a function, it\u0026rsquo;s called a method.\nThe following contents are from Chapter 7 of the textbook.\nProcedural vs. object-oriented programming Procedural programs look at the world in terms of two entities, \u0026ldquo;data\u0026rdquo; and \u0026ldquo;functions\u0026rdquo;. In a procedural context, the two entities are separate from each other. A function takes data as input and returns data as output. In the real world, however, we don\u0026rsquo;t think data and functions as separate entities. That is, real world objects instead have both \u0026ldquo;state\u0026rdquo; and \u0026ldquo;behaviors\u0026rdquo;. For instance, people have state (tall, short, etc.) and behavior (playing basketball, running, etc.), often both at the same time, and, of course, in the same person.\nThe nuts and bolts of objects An object in programming is an entity or \u0026ldquo;variable\u0026rdquo; that has two entities attached to it: data (attributes) and things that act on that data (methods). Importantly, you design methods to act on the attributes; they aren’t random functions someone has attached to the object.\nThe key syntax idea of objects is borrowed from module syntax: Just as you describe functions attached to modules by giving the module name, a period, then the function name, you describe things attached to a Python object by giving the variable name, a period, then the attribute or method name.\nThe variable types (e.g. string) we covered are in fact objects. Python includes these objects because they are used frequently. In Python, this common pattern or template is defined by the class statement. Using predefined classes, we create new variables and these specific realizations of that pattern are called \u0026ldquo;instances of that class.\u0026rdquo;\nExample of how objects work: Strings Python strings (like nearly everything else in Python) are objects. Thus, built into Python, there (implicitly) is a class definition of the string class, and every time you create a string, you are using that definition as your template. That template defines both attributes and methods for all string objects, so whatever string you\u0026rsquo;ve created, you have that set of data and functions attached to your string which you can use.\nLet\u0026rsquo;s create a string variables.\na = \u0026quot;hello world\u0026quot;  To see all attributes and methods, you can use dir() (You can still use dir() in IPython).\n\u0026gt;\u0026gt;\u0026gt; a = \u0026quot;hello world\u0026quot; \u0026gt;\u0026gt;\u0026gt; dir(a) ['__add__', '__class__', '__contains__', '__delattr__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getslice__', '__gt__', '__hash__', '__init__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_formatter_field_name_split', '_formatter_parser', 'capitalize', 'center', 'count', 'decode', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'index', 'isalnum', 'isalpha', 'isdigit', 'islower', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']  The string class has many methods attached to it. Let\u0026rsquo;s try a.upper()\n\u0026gt;\u0026gt;\u0026gt; a.upper() 'HELLO WORLD'  If you try a.title()\n\u0026gt;\u0026gt;\u0026gt; a.title() 'Hello World'  These upper and title functions only works for string variables because they are defined under the string class. If you try to use them for an integer variable,\n\u0026gt;\u0026gt;\u0026gt; b = 5 \u0026gt;\u0026gt;\u0026gt; b.title() Traceback (most recent call last): File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; AttributeError: 'int' object has no attribute 'title' \u0026gt;\u0026gt;\u0026gt; b.upper() Traceback (most recent call last): File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; AttributeError: 'int' object has no attribute 'upper'  With dir(a), you can get the attributes starting with double underscores, e.g. __doc__.\n\u0026gt;\u0026gt;\u0026gt; a.__doc__ \u0026quot;str(object='') -\u0026gt; str\\nstr(bytes_or_buffer[, encoding[, errors]]) -\u0026gt; str\\n\\nCreate a new string object from the given object. If encoding or\\nerrors is specified, then the object must expose a data buffer\\nthat will be decoded using the given encoding and error handler.\\nOtherwise, returns the result of object.__str__() (if defined)\\nor repr(object).\\nencoding defaults to sys.getdefaultencoding().\\nerrors defaults to 'strict'.\u0026quot;  In IPython, a.__doc__ is printed out as docstring when you do a?.\nIn [1]: a = \u0026quot;hello world\u0026quot; In [2]: a? Type: str String form: hello world Length: 11 Docstring: str(object='') -\u0026gt; str str(bytes_or_buffer[, encoding[, errors]]) -\u0026gt; str Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.__str__() (if defined) or repr(object). encoding defaults to sys.getdefaultencoding(). errors defaults to 'strict'.  Other information such as str, hello world and 11 can be obtained by a.__class__, a.__str__() and a.__len__(), respectively.\nAttributes of the string class can also have their own attributes. For example,\n\u0026gt;\u0026gt;\u0026gt; a=\u0026quot;hello world\u0026quot; \u0026gt;\u0026gt;\u0026gt; dir(a.upper) ['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__self__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__text_signature__']  You can access one of the attributes of an attribute using another period followed by the name of the attribute as the following.\n\u0026gt;\u0026gt;\u0026gt; a.upper.__doc__ 'S.upper() -\u0026gt; str\\n\\nReturn a copy of S converted to uppercase.'  Exercise In the Python interpreter, type in:\na = 'The rain in Seoul.'  Given string a:\n Create a new string b that is a but all in uppercase. Is a changed when you create b? How would you test to see whether b is in uppercase? That is, how could you return a boolean that is True or False depending on whether b is uppercase? How would you calculate the number of occurrences of the letter “n” in a?    "
},
{
	"uri": "https://hajsong.github.io/ATM4110/python/myclass/",
	"title": "Defining class",
	"tags": ["class", "object"],
	"description": "",
	"content": " \u0026ldquo;Classes provide a means of bundling data and functionality together.\u0026rdquo; (from the Python documentation)\nWe can define our own type of object by creating a new class that can carry attributes and methods to maintaining and modifying its state.\nWhen we define a new variable, we actually create a new instance of a class. For example, typing a = 'hello' creates an instance of a predefined string class. Likewise, we can create a new class instance that has the format of the class we defined.\nClass definition syntax The simplest form of class definition looks like this:\nclass ClassName: \u0026lt;statement-1\u0026gt; . . . \u0026lt;statement-N\u0026gt;  Class definitions start with class statement. The definition of the class follows from the next line with indentations at the beginning of the lines. Definition of the class must be done before using it. The \u0026lt;statement-i\u0026gt; in the class definition can be method definitions as well as attribute statements.\nClass objects Class objects support two kinds of operations: attribute references and instantiation.\nAttribute references are defined as obj.name. For example,\nclass MyClass: \u0026quot;\u0026quot;\u0026quot; A simple example class \u0026quot;\u0026quot;\u0026quot; i = 100 def f(self): return 'hello'  Within the definition, you refer to the instance of the class as self. So, you can refer to the attribute defined earlier as self.\u0026lt;attribute name\u0026gt;, and the method (or function) as self.\u0026lt;method name\u0026gt; (e.g. self.data or self.calculate).\nIn this example, the class MyClass has attributes, i that returns an integer, and f() that is a function object. These attributes are referred to MyClass.i and MyClass.f, respectively. There is another attribute: __doc__ returns the docstring enclosed with three double quotation marks.\nClass instantiation uses function notation. To create an instance x in the class MyClass, you can simply type as the following:\nx = MyClass()  Then, you can access the attributes as the following:\nx.i x.f()  Or you can also get attributes with\nMyClass.i MyClass.f(x)  The expression is consistent with the f() definition.\nWhen you create an instance of your own object, you may want to customize the initialization of the instance. This method is called whenever you create an instance of the class, and so you usually put code that handles the arguments present when you create (or instantiate) an instance of a class and conducts any kind of initialization for the object instance.\nclass MyClass: \u0026quot;\u0026quot;\u0026quot; A simple example class \u0026quot;\u0026quot;\u0026quot; def __init__(self): self.data = [] i = 100 def f(self): return 'hello'  If you create a variable with this class, you can see additional attribute, data.\nx = MyClass() print(x.data)  The example above does not take any inputs and the initialization of x doesn\u0026rsquo;t do anything but creating a space called data. The following example now takes an input to initialize the instant x.\nclass MyClass: \u0026quot;\u0026quot;\u0026quot; A simple example class \u0026quot;\u0026quot;\u0026quot; def __init__(self, data): self.data = data i = 100 def f(self): return 'hello'  If you try to create a new variable x as above, you will get an error.\n\u0026gt;\u0026gt;\u0026gt; x = MyClass() Traceback (most recent call last): File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; TypeError: __init__() missing 1 required positional argument: 'data'  Instead, you can create x by providing the initial value.\n\u0026gt;\u0026gt;\u0026gt; x = MyClass(10) \u0026gt;\u0026gt;\u0026gt; print(x.data) 10  A Practical Example This class provides a template for holding and manipulating information about a book. The class definition provides a single method (besides the initialization method) that returns a formatted bibliographic reference for the book. The code below gives the class definition and then creates two instances of the class (note line continuations are added to fit the code on the page):\nclass Book(object): \u0026quot;\u0026quot;\u0026quot; Objective : This class organizes the information of books \u0026quot;\u0026quot;\u0026quot; def __init__(self, authorlast, authorfirst, \\ title, place, publisher, year): self.authorlast = authorlast self.authorfirst = authorfirst self.title = title self.place = place self.publisher = publisher self.year = year def write_bib_entry(self): return self.authorlast \\ + ', ' + self.authorfirst \\ + ', ' + self.title \\ + ', ' + self.place \\ + ': ' + self.publisher + ', ' \\ + self.year + '.'  Line 1 begins the class definition. By convention, class names follow the CapWords convention (capitalize the first letter of every word). The argument in the class statement is a special object called object. This has to do with the objective-oriented project idea, which is a topic beyond the scope of this class. In Python3, you can skip object as in the MyClass example, but please read this page for more information.\nLine 2-4 contains docstring. In IPython, after defining Book class, you can check the docstring with\nIn [2]: Book? Init signature: Book(authorlast, authorfirst, title, place, publisher, year) Docstring: Objective : This class organizes the information of books Type: type  The arguments list of __init__ is the list of arguments passed in to the constructor of the class, which is called when you use the class name with calling syntax.\nYou can define instances as the following.\nbeauty = Book( \u0026quot;Dubay\u0026quot;, \u0026quot;Thomas\u0026quot; \\ , \u0026quot;The Evidential Power of Beauty\u0026quot; \\ , \u0026quot;San Francisco\u0026quot; \\ , \u0026quot;Ignatius Press\u0026quot;, \u0026quot;1999\u0026quot; ) pynut = Book( \u0026quot;Martelli\u0026quot;, \u0026quot;Alex\u0026quot; \\ , \u0026quot;Python in a Nutshell\u0026quot; \\ , \u0026quot;Sebastopol, CA\u0026quot; \\ , \u0026quot;O'Reilly Media, Inc.\u0026quot;, \u0026quot;2003\u0026quot; )  Then, you can get the formatted output of the book information.\nIn [4]: pynut.write_bib_entry() Out[4]: \u0026quot;Martelli, Alex, Python in a Nutshell, Sebastopol, CA: O'Reilly Media, Inc., 2003.\u0026quot;  It is noted that the write_bib_entry method is called with no input parameters, but in the class definition, I still need to provide it with self as an input. That way, the method definition is able to make use of all the attributes and methods attached to self.\nIn defining the class, you need to be consistent with indentation. Try the following example.\nclass Book(object): def __init__(self, authorlast, authorfirst, \\ title, place, publisher, year): self.authorlast = authorlast self.authorfirst = authorfirst self.title = title self.place = place self.publisher = publisher self.year = year def write_bib_entry(self): return self.authorlast \\ + ', ' + self.authorfirst \\ + ', ' + self.title \\ + ', ' + self.place \\ + ': ' + self.publisher + ', ' \\ + self.year + '.'  Does the Book class have the method write_bib_entry?\nIn the example above, we defined a function, write_bib_entry. It is not a part of Book, so that when you try\nIn [5]: pynut.write_bib_entry() --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) \u0026lt;ipython-input-10-de7a795a67da\u0026gt; in \u0026lt;module\u0026gt;() ----\u0026gt; 1 pynut.write_bib_entry() AttributeError: 'Book' object has no attribute 'write_bib_entry'  But,\nIn [6]: write_bib_entry(pynut) Out[6]: \u0026quot;Martelli, Alex, Python in a Nutshell, Sebastopol, CA: O'Reilly Media, Inc., 2003.\u0026quot;  Why does this work? What is the role of self in write_bib_entry?\nexercise  How would you print out the author attribute of the pynut instance (at the interpreter, after running the file)? If you type print beauty.write_bib_entry() at the interpreter (after running the file), what will happen? How would you change the publication year for the beauty book to \u0026quot;2010\u0026quot;?  Remarks on class  It is not necessary that the function definition is textually enclosed in the class definition: assigning a function object to a local variable in the class is also ok. For example:  # Function defined outside the class def f1(self, x, y): return min(x, x+y) class C: f = f1 def g(self): return 'hello world' h = g  Then C has three attributes, f, g, and h. f requires two inputs to determine the minimum number, but g and h need no input (and they are identical).\n Methods may call other methods by using method attributes of the self argument:  class Bag: def __init__(self): self.data = [] def add(self, x): self.data.append(x) def addtwice(self, x): self.add(x) self.add(x)  In the method addtwice, the method add was called.\nIn [12]: y = Bag() In [13]: y.add(3) In [14]: y.data Out[14]: [3] In [15]: y.addtwice(4) In [16]: y.data Out[16]: [3, 4, 4]   Defining empty class can be done.  class Employee: pass john = Employee() # Create an empty employee record # Fill the fields of the record john.name = 'John Doe' john.dept = 'computer lab' john.salary = 1000   You can use its own class in the definition. ``` from math import sqrt  class Rocket(): # Rocket simulates a rocket ship for a game, # or a physics simulation.\ndef __init__(self, x=0, y=0): # Each rocket has an (x,y) position. self.x = x self.y = y def move_rocket(self, x_increment=0, y_increment=1): # Move the rocket according to the paremeters given. # Default behavior is to move the rocket up one unit. self.x += x_increment self.y += y_increment def get_distance(self, other_rocket): # Calculates the distance from this rocket to another rocket, # and returns that value. distance = sqrt((self.x-other_rocket.x)**2+(self.y-other_rocket.y)**2) return distance  The method ```get_distance``` takes the positional argument ```other_rocket``` which is also ```Rocket``` class.  Make two rockets, at different places. rocket_0 = Rocket() rocket_1 = Rocket(10,5)\nShow the distance between them. distance = rocket_0.get_distance(rocket_1) print(\u0026ldquo;The rockets are %f units apart.\u0026rdquo; % distance) ```\nObject-Oriented programming We are using the example script that can be downloaded from here\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/environment/howtouse/",
	"title": "Start Python / Jupyter Notebook",
	"tags": ["python", "jupyter notebook"],
	"description": "",
	"content": " This page guides you how to use Python and Jupyter Notebook using the example, Celsius and Fahrenheit converter.\nWhen you want to convert the unit from Fahrenheit to Celsius, the formula is:\n\nFrom Celsius to Fahrenheit, the formula is:\n\nPython To start Python, you can type python in the terminal.\n$ python  Then you may see that the prompt has been changed as\nPython 3.6.3 |Anaconda, Inc.| (default, Oct 6 2017, 12:04:38) [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)] on darwin Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt;  Ask for the input in Celsius:\n\u0026gt;\u0026gt;\u0026gt; TinC = int(input(\u0026quot;Enter a temperature in Celsius: \u0026quot;))  Then you can see the next line asking a temperature in Celsius.\nEnter a temperature in Celsius:  We can say 30, although you can give any number. Then TinC carries 30. Next is to convert temperature from Celsius to Fahrenheit using the formula.\n\u0026gt;\u0026gt;\u0026gt; TinF = 9.0/5.0 * TinC + 32  It is time to print out the answer.\n\u0026gt;\u0026gt;\u0026gt; print(\u0026quot;Temperature:\u0026quot;, TinC, \u0026quot;degC = \u0026quot;, TinF, \u0026quot;degF\u0026quot;)  This should give you\nTemperature: 30 degC = 86.0 degF  Once you are done, you can exit Python by typing quit()\n\u0026gt;\u0026gt;\u0026gt; quit()  Make the unit converter from Fahrenheit to Celsius by yourself.  IPython Interactive Python (IPython) gives you more functionality by providing a wider range of commands than python. To launch IPython, simply type\n$ ipython  This will give you\nPython 3.6.3 |Anaconda, Inc.| (default, Oct 6 2017, 12:04:38) Type 'copyright', 'credits' or 'license' for more information IPython 6.1.0 -- An enhanced Interactive Python. Type '?' for help. In [1]:  Here, you can follow the same procedure as in python to have the program of the unit converter.\nIn [1]: TinC = int(input(\u0026quot;Enter a temperature in Celsius: \u0026quot;)) Enter a temperature in Celsius: 30 In [2]: TinF = 9.0/5.0 * TinC + 32 In [3]: print(\u0026quot;Temperature:\u0026quot;, TinC, \u0026quot;degC = \u0026quot;, TinF, \u0026quot;degF\u0026quot;) Temperature: 30 degC = 86.0 degF  As already mentioned above, IPython provides useful functions. For example, if you want to know about the command input, you can type\nIn [4]: input?  If you want to know what variables are defined, type\nIn [5]: whos Variable Type Data/Info ----------------------------- TinC int 30 TinF float 86.0  IPython also provides many magic functions. The built-in magics include:\n Functions that work with code: %run, %edit, %save, %macro, %recall, etc. Functions which affect the shell: %colors, %xmode, %autoindent, %automagic, etc. Other functions such as %reset, %timeit, %%writefile, %load, or %paste.  You can always call them using the % prefix, and if you’re calling a line magic on a line by itself, you can omit %. For more information about built-in magic commands, please refer to IPython webpage\nTo exit IPython, you can do either quit or exit.\nPython script If the job requires more than a few lines of python codes, then typing commands can be overwhelming. Also, it is likely that you make mistakes. In this case, writing all python commands in a python script and running this script to get the result is the way to go.\nThe first thing to do is create a python script file using text editors. If you use vim, you can easily create a file by typing vim filename.py.\n$ vim ctof.py  Then write all python codes there.\n# This script converts temperature in Celsius to temperature in Fahrenheit. # # 2018.9.13 TinC = int(input(\u0026quot;Enter a temperature in Celsius: \u0026quot;)) TinF = 9.0/5.0 * TinC + 32 print(\u0026quot;Temperature:\u0026quot;, TinC, \u0026quot;degC = \u0026quot;, TinF, \u0026quot;degF\u0026quot;)  In this example, the first three lines start with #. Whenever a line starts with #, python just skips it. So it is useful to add an explanation of your code in the script file.\nYou can execute this script in a few different ways.\n1. In Python After launching python, you can execute your python script as follows.\n\u0026gt;\u0026gt;\u0026gt; exec(open('ctof.py').read())  If you input temperature in Celsius when it asks temperature, you can get the result.\nEnter a temperature in Celsius: 30 Temperature: 30 degC = 86.0 degF  If you think that this is not a really convenient way to run the program, there are alternative ways.\n2. In IPython Running a python script in IPython is much easier than in Python. After launching IPython with ipython, you can just type\nIn [1]: %run ctof.py  to get the same result as in python. You can even drop the file extension.\nIn [2]: %run ctof  even just run ctof.py or run ctof will do the job!\nAnother way to run the script, copy whole lines and paste them in IPython. To paste copied lines in IPython, you can use a magic function %paste.\nIn [3]: %paste  Then IPython shows the copied lines below. This is particularly useful if you need to run a few lines of your python script.\nIPython allows you to open the text file with an exclamation mark (!) while you are in IPython.\nIn [5]: !vim ctof.py  This makes %paste really useful because you can open your script and get the necessary lines without leaving IPython.\n3. Using Python in the terminal You do not launch python to execute python scripts. In the terminal, you can run your script by\n$ python ctof.py  4. As stand-alone in the terminal If your script starts with\n#!/usr/bin/env python3  you can run this script without typing python in the terminal. When you save the script, make sure to change file modes to be executable.\n$ chmod 755 ctof.py  To run this executable file,\n$ ./ctof.py  Jupyter Notebook You can use Jupyter Notebook for running python commands or a script. First, launch Jupyter Notebook.\n$ jupyter notebook  Then you get to have a new window in your web browser showing the file system in the working directory. To start python, click new in the upper right corner and select Python 3. This will open a new tab that just looks like IPython.\nJupyter Notebook consists of cells. It is your choice how to compose the cell with your commands. You can add all the lines in one cell, or a simple line for each cell.\nLet\u0026rsquo;s first copy all the lines in a single cell. Jupyter Notebook provides a help page, and it says that you can hit control key and enter key together to run the cell. When you run the cell, you are asked to give temperature in Celsius as before.\nIf we decide to use cells for each line, you will be asked to give temperature after run the cell with TinC = int(input(\u0026quot;Enter a temperature in Celsius: \u0026quot;)).\nOnce you are done, you can save the Jupyter Notebook file in the web browser.\nTo finish Jupyter Notebook, you can come back to the terminal where you typed jupyter notebook and hit ^C TWICE!\nIn the class, we can explore what Jupyter Notebook offers extensively.\nLaunch Jupyter Notebook remotely In some cases, you need to use a remote server for Jupyter Notebook. In the remote server,\n$ jupyter notebook --no-browser --port=8889  This launches Jupyter Notebook without opening web browser. Then on your local machine,\n$ ssh -N -f -L localhost:8899:localhost:8889 [accountname]@[servername]  and open the browser and go to http://localhost:8899 The web browser ask for the key, and you can find it in the terminal where you launch Jupyter Notebook.\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/python/array1/",
	"title": "Array operation 1",
	"tags": ["array", "numpy"],
	"description": "",
	"content": " We handled list variables in the previous chapter, and we can add any types of data to the list, even another list! The computational overhead to support that flexibility, however, is non-trivial, and so lists are not practical to use for most scientific computing problems.\nIn other words, lists are too slow.\nTo solve this problem, Python has a package called NumPy which defines an array data type that in many ways is like the array data type in Fortran.\nAn array is like a list except: All elements are of the same type, so operations with arrays are much faster; multi-dimensional arrays are more clearly supported; and array operations are supported. To utilize NumPy’s functions and attributes, you import the package numpy. Because NumPy functions are often used in scientific computing, you usually import NumPy as an alias, e.g., import numpy as N or import numpy as np, to save yourself some typing. In the following context, it is assumed that the NumPy package is imported as np.\nCreating arrays The most basic way of creating an array is to take an existing list and convert it into an array using the array function in NumPy.\nmylist = [[2, 3, -5],[21, -2, 1]] myarray = np.array(mylist)   What does it happen when you try to convert the list [[2, 3, -5],[21, -2]]?  A row vector and a column vector can be made differently.\na = np.array([2, 3, 4]) # an array with three element b = np.array([[2, 3, 4]]) # a 1x3 row vector c = np.array([[2], [3], [4]]) # a 3x1 column vector  Sometimes you will want to make sure your NumPy array elements are of a specific type. To force a certain numerical type for the array, set the dtype keyword to a type code:\na = np.array(mylist, dtype='d')  where the string \u0026ldquo;d\u0026rdquo; is the typecode for double-precision floating point. Other options you have are\n f : single precision floating i : short integer l : long integer  To see the difference between single precision and double precision, let\u0026rsquo;s try\n\u0026gt;\u0026gt;\u0026gt; b = np.array(10./3., dtype = 'd') \u0026gt;\u0026gt;\u0026gt; c = np.array(10./3., dtype = 'f') \u0026gt;\u0026gt;\u0026gt; print(b) \u0026gt;\u0026gt;\u0026gt; print(c)  np.array is the function that create a variable with the array object called ndarray.  Often you will find the moment when you want to create an array of a specific size but with unknown or undetermined values. In this case, you can use either zeros or empty functions.\na = np.zeros((3, 2), dtype = 'd')  or\na = np.zeros([3, 2], dtype = 'd')    How do np.zeros and np.empty differ?   Here is the answer from stackoverflow:\n empty() does not initialize the memory, therefore your array will be filled with garbage and you will have to initialize all cells. zeros() initializes everything to 0. Therefore, if your final result includes lots of zeros, this will save you the time to set all those array cells to zero manually.    Another array you will commonly create is the array whose elements increase or decrease monotonically. In this case, you can use the arange function.\n\u0026gt;\u0026gt;\u0026gt; a = np.arange(10) \u0026gt;\u0026gt;\u0026gt; print(a) [0 1 2 3 4 5 6 7 8 9]  The array a has 10 integer elements. What if you want to create an array with floating numbers?\nIn [10]: a = np.arange(10.0) In [11]: b = np.arange(10, dtype = 'f') In [12]: print(a) [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.] In [13]: print(b) [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.] In [14]: whos Variable Type Data/Info ------------------------------- a ndarray 10: 10 elems, type `float64`, 80 bytes b ndarray 10: 10 elems, type `float32`, 40 bytes np module \u0026lt;module 'numpy' from '/Us\u0026lt;...\u0026gt;kages/numpy/__init__.py'\u0026gt;  In case you want to create an 3 by 4 array with random numbers,\nIn [22]: np.random.random((3,4)) Out[22]: array([[0.59544951, 0.38485189, 0.42626703, 0.38313338], [0.51624656, 0.04025792, 0.65402374, 0.70589402], [0.1984409 , 0.8254778 , 0.25162249, 0.89099201]])  It is noted that np.random is a submodule and it has a method called random.\nArray indexing Like lists, element addresses start with zero, so the first element of a 1-D array a is a[0], the second is a[1], etc. You can also reference elements starting from the end, e.g., element a[-1] is the last element in a 1-D array a.\nArray slicing follows rules very similar to list slicing:\n Element addresses in a range are separated by a colon. The lower limit is inclusive, and the upper limit is exclusive. If one of the limits is left out, the range is extended to the end of the range (e.g., if the lower limit is left out, the range extends to the very beginning of the array). Thus, to specify all elements, use a colon by itself.  In [14]: a = np.array([2, 3.2, 5.5, -6.4, -2.2, 2.4]) In [15]: print(a[1]) 3.2 In [16]: print(a[1:4]) [ 3.2 5.5 -6.4] In [17]: print(a[2:]) [ 5.5 -6.4 -2.2 2.4] In [18]: print(a[-2:]) [-2.2 2.4]  For multi-dimensional arrays, indexing between different dimensions is separated by commas. Note that the fastest varying dimension is always the last index, the next fastest varying dimension is the next to last index, and so forth (this follows C convention). Thus, a 2-D array is indexed [row, col]. Slicing rules also work as applied for each dimension (e.g., a colon selects all elements in that dimension). Here’s an example:\n\u0026gt;\u0026gt;\u0026gt; a = np.array([[2, 3.2, 5.5, -6.4, -2.2, 2.4], [1, 22, 4, 0.1, 5.3, -9], [3, 1, 2.1, 21, 1.1, -2]]) \u0026gt;\u0026gt;\u0026gt; print(a) [[ 2. 3.2 5.5 -6.4 -2.2 2.4] [ 1. 22. 4. 0.1 5.3 -9. ] [ 3. 1. 2.1 21. 1.1 -2. ]]  Then, what is a[1,2]? How about a[:,3]? a[1,:]? a[1,1:4]?\n\u0026gt;\u0026gt;\u0026gt; print(a[1,2]) 4.0 \u0026gt;\u0026gt;\u0026gt; print(a[:,3]) [-6.4 0.1 21. ] \u0026gt;\u0026gt;\u0026gt; print(a[1,:]) [ 1. 22. 4. 0.1 5.3 -9. ] \u0026gt;\u0026gt;\u0026gt; print(a[1,1:4]) [22. 4. 0.1]  It is also possible to get, for example, every other elements or every third elements.\nIn [13]: a[1,::2] Out[13]: array([1. , 4. , 5.3])  Python reverses the order if we give a negative number after two colons.\nIn [14]: a[1,::-1] Out[14]: array([-9. , 5.3, 0.1, 4. , 22. , 1. ])  The extraction of the element can be possible by passing the list of the index.\nIn [84]: i = [1, 3, 4] In [85]: a[2,i] Out[85]: array([ 1. , 21. , 1.1])  How about this?\nIn [7]: j = [0,1] In [8]: i = [2,4] In [9]: a[j,i]  This will give you the elements at the index (0,2) and (1,4) so that\nOut[9]: array([5.5, 5.3])  Suppose you want to extract all elements that are at the first two rows and the third and fifth columns.\nIn [11]: a[j,:] Out[11]: array([[ 2. , 3.2, 5.5, -6.4, -2.2, 2.4], [ 1. , 22. , 4. , 0.1, 5.3, -9. ]]) In [12]: a[j][:,i] Out[12]: array([[ 5.5, -2.2], [ 4. , 5.3]])  Array inquiry Arrays in Python are eventually object to which a list of attributes and methods are attached. Here are some of functions for the array inquiry.\nFor the 2-D array a where\na = np.array([[2, 3.2, 5.5, -6.4, -2.2, 2.4], [1, 22, 4, 0.1, 5.3, -9], [3, 1, 2.1, 21, 1.1, -2]])  To get the size of the array, one can use np.shape(a) that gives (3, 6) in this example. If we want to know the total number of elements in the array, np.size(a) gives 18. It is noted that len(a) function that was used for list variables will return 3. To find out the data type, try a.dtype.char.\nArray manipulation In addition to finding things about an array, NumPy includes many functions to manipulate arrays. Some, like transpose, come from linear algebra, but NumPy also includes a variety of array manipulation functions that enable you to modify arrays into the form you need to do the calculations you want.\nCopying Let\u0026rsquo;s suppose we want to copy the array a to b as b = a. Then change the element b[0,0] = -2.0. What happens to a?\nIn [13]: b = a In [14]: b[0,0] = -2.0 In [15]: print(b) [[-2. 3.2 5.5 -6.4 -2.2 2.4] [ 1. 22. 4. 0.1 5.3 -9. ] [ 3. 1. 2.1 21. 1.1 -2. ]] In [16]: print(a) [[-2. 3.2 5.5 -6.4 -2.2 2.4] [ 1. 22. 4. 0.1 5.3 -9. ] [ 3. 1. 2.1 21. 1.1 -2. ]]  Interestingly, the array a is also changed and a and b are the same! In Python, the equal sign is not copying variables.\nTo copy the array, we can use the function, np.copy.\nIn [3]: b = a.copy() In [4]: b[0,0] = -2.0 In [5]: print(b) [[-2. 3.2 5.5 -6.4 -2.2 2.4] [ 1. 22. 4. 0.1 5.3 -9. ] [ 3. 1. 2.1 21. 1.1 -2. ]] In [6]: print(a) [[ 2. 3.2 5.5 -6.4 -2.2 2.4] [ 1. 22. 4. 0.1 5.3 -9. ] [ 3. 1. 2.1 21. 1.1 -2. ]]  This also applies to the list. To copy the list variable a to b, do b = a.copy(). Transpose The transpose of an array a can be done with np.transpose(a) or a.T:\nIn [44]: np.transpose(a) Out[44]: array([[ 2. , 1. , 3. ], [ 3.2, 22. , 1. ], [ 5.5, 4. , 2.1], [-6.4, 0.1, 21. ], [-2.2, 5.3, 1.1], [ 2.4, -9. , -2. ]]) In [45]: a.T Out[45]: array([[ 2. , 1. , 3. ], [ 3.2, 22. , 1. ], [ 5.5, 4. , 2.1], [-6.4, 0.1, 21. ], [-2.2, 5.3, 1.1], [ 2.4, -9. , -2. ]])  If we define an array as in the first example and transpose it, there is no change.\nIn [59]: a = np.arange(5) In [60]: print(a) [0 1 2 3 4] In [61]: print(a.T) [0 1 2 3 4]  To make the transpose effective, the array has to be a vector or a multi-dimensional array.\nIn [62]: b = np.array([[2, 3, 4]]) # a row vector In [63]: print(b) [[2 3 4]] In [64]: print(b.T) [[2] [3] [4]] In [65]: c = np.array([[2], [3], [4]]) # a column vector In [66]: print(c) [[2] [3] [4]] In [67]: print(c.T) [[2 3 4]]  Convert from N-D to 1-D array We can make a N-dimensional array to a 1-D array or a vector. There are two functions that make this happen : ravel and flatten.\nIn [5]: np.ravel(a) Out[5]: array([ 2. , 3.2, 5.5, -6.4, -2.2, 2.4, 1. , 22. , 4. , 0.1, 5.3, -9. , 3. , 1. , 2.1, 21. , 1.1, -2. ]) In [6]: a.ravel() Out[6]: array([ 2. , 3.2, 5.5, -6.4, -2.2, 2.4, 1. , 22. , 4. , 0.1, 5.3, -9. , 3. , 1. , 2.1, 21. , 1.1, -2. ]) In [7]: a.flatten() Out[7]: array([ 2. , 3.2, 5.5, -6.4, -2.2, 2.4, 1. , 22. , 4. , 0.1, 5.3, -9. , 3. , 1. , 2.1, 21. , 1.1, -2. ])  The function flatten is built-in in the NumPy array class, and it is not possible to use as np.flatten(a).\nAnother important difference between two is that while flatten copies the array, ravel doesn\u0026rsquo;t.\nIn [34]: a_r = a.ravel() In [35]: a_f = a.flatten() In [36]: a_f = a.flatten() In [37]: a_f[3] = 10 In [38]: print(a_f) [ 2. 3.2 5.5 10. -2.2 2.4 1. 22. 4. 0.1 5.3 -9. 3. 1. 2.1 21. 1.1 -2. ] In [39]: print(a) [[ 2. 3.2 5.5 -6.4 -2.2 2.4] [ 1. 22. 4. 0.1 5.3 -9. ] [ 3. 1. 2.1 21. 1.1 -2. ]] In [40]: a_r = a.ravel() In [41]: a_r[3] = 10 In [43]: print(a_r) [ 2. 3.2 5.5 10. -2.2 2.4 1. 22. 4. 0.1 5.3 -9. 3. 1. 2.1 21. 1.1 -2. ] In [44]: print(a) [[ 2. 3.2 5.5 10. -2.2 2.4] [ 1. 22. 4. 0.1 5.3 -9. ] [ 3. 1. 2.1 21. 1.1 -2. ]]  Reshaping We can convert the shape of the array as long as we keep the size the same.\nOut[50]: array([[ 2. , 3.2], [ 5.5, -6.4], [-2.2, 2.4], [ 1. , 22. ], [ 4. , 0.1], [ 5.3, -9. ], [ 3. , 1. ], [ 2.1, 21. ], [ 1.1, -2. ]]) In [51]: a.reshape(9,2) Out[51]: array([[ 2. , 3.2], [ 5.5, -6.4], [-2.2, 2.4], [ 1. , 22. ], [ 4. , 0.1], [ 5.3, -9. ], [ 3. , 1. ], [ 2.1, 21. ], [ 1.1, -2. ]])  Concatenation Concatenation, or joining of two arrays in NumPy, is primarily accomplished using the routines np.concatenate, np.vstack, and np.hstack. np.concatenate takes a tuple or list of arrays as its first argument, as we can see here:\nIn [46]: x = np.array([1, 2, 3]) In [47]: y = np.array([3, 2, 1]) In [48]: np.concatenate([x, y]) Out[48]: array([1, 2, 3, 3, 2, 1])  You can concatenate more than two arrays.\nIn [49]: np.concatenate([x, y, x]) Out[49]: array([1, 2, 3, 3, 2, 1, 1, 2, 3])  And even 2-D arrays.\nIn [60]: a = np.arange(6).re(2,3) In [61]: print(a) [[0 1 2] [3 4 5]] In [62]: np.concatenate((a, a)) Out[62]: array([[0, 1, 2], [3, 4, 5], [0, 1, 2], [3, 4, 5]])  We can control the axis along which the arrays are concatenated.\nIn [63]: np.concatenate((a, a), axis=1) Out[63]: array([[0, 1, 2, 0, 1, 2], [3, 4, 5, 3, 4, 5]])  In some cases, vstack and hstack functions are more intuitive.\nIn [64]: np.vstack((a, a)) Out[64]: array([[0, 1, 2], [3, 4, 5], [0, 1, 2], [3, 4, 5]]) In [65]: np.hstack((a, a)) Out[65]: array([[0, 1, 2, 0, 1, 2], [3, 4, 5, 3, 4, 5]])  Repetition When repeating each element is desired, repeat function is the right choice.\nIn [66]: print(d) [[0. 1. 2.] [3. 4. 5.]] In [67]: np.repeat(a,3) Out[67]: array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5])  By default, it use the flattened input array, and return a flat output array. We can specify the axis along which to repeat values.\nIn [76]: np.repeat(a,3, axis=0) Out[76]: array([[0, 1, 2], [0, 1, 2], [0, 1, 2], [3, 4, 5], [3, 4, 5], [3, 4, 5]]) In [77]: np.repeat(a,3, axis=1) Out[77]: array([[0, 0, 0, 1, 1, 1, 2, 2, 2], [3, 3, 3, 4, 4, 4, 5, 5, 5]])  Convert type The type of elements of the array can be converted using astype function.\nIn [69]: d = a.astype('f') In [70]: print(d) [[0. 1. 2.] [3. 4. 5.]]  Creating arrays representing the grid information of data In the atmospheric and oceanic sciences, we often find ourselves using 2-D regularly gridded slices of data where the x-and y-locations of each array element is given by the corresponding elements of the x and y vectors. Wouldn\u0026rsquo;t it be nice to get a 2-D array whose elements are the x-values for each column and a 2-D array whose elements are the y-values for each row? The meshgrid function does just that.\nLet\u0026rsquo;s first create vectors for longitude and latitude with the space of 5 degrees.\nIn [2]: lon = np.arange(-180, 180, 5) In [3]: lat = np.arange(-90, 91, 5)  According to the indexing rule in Python, lon starts from -180 with the increment of 5 but stops just before 180. That means that 180 is not a part of the array lon. On the other hand, lat stops at 91, so it includes 90.\nTo create 2-D arrays for longitude and latitude,\nIn [4]: [X, Y] = np.meshgrid(lon, lat) # or X, Y = np.meshgrid(lon, lat) In [5]: print(X) [[-180 -175 -170 ... 165 170 175] [-180 -175 -170 ... 165 170 175] [-180 -175 -170 ... 165 170 175] ... [-180 -175 -170 ... 165 170 175] [-180 -175 -170 ... 165 170 175] [-180 -175 -170 ... 165 170 175]] In [6]: print(Y) [[-90 -90 -90 ... -90 -90 -90] [-85 -85 -85 ... -85 -85 -85] [-80 -80 -80 ... -80 -80 -80] ... [ 80 80 80 ... 80 80 80] [ 85 85 85 ... 85 85 85] [ 90 90 90 ... 90 90 90]]  You may have just one output\nIn [7]: G = np.meshgrid(lon, lat) In [8]: G? Type: list String form: [array([[-180, -175, -170, ..., 165, 170, 175], [-180, -175, -170, ..., 165, 170, 17 \u0026lt;...\u0026gt; , 80], [ 85, 85, 85, ..., 85, 85, 85], [ 90, 90, 90, ..., 90, 90, 90]])] Length: 2 Docstring: list() -\u0026gt; new empty list list(iterable) -\u0026gt; new list initialized from iterable's items  As you can see, meshgrid returns the list variable G, and G[0] is equivalent to X and G[1] to Y.\nWhen dealing with a 3-D data set, you need to include the third axis which is usually either height or depth.\nIn [9]: lev = np.array([0, 250, 500, 850, 1000])  Here, we want to replicate lev for each horizontal grid point. NumPy provides a function called tile to make this happen.\nFor X and Y,\nIn [71]: nz = len(lev) In [72]: XX = np.tile(X, [nz, 1, 1]) In [73]: YY = np.tile(Y, [nz, 1, 1])  For Z,\nIn [10]: ny, nx = X.shape In [11]: Z = np.tile(lev, [ny, nx, 1]) In [12]: print(Z.shape) (37, 72, 5) In [13]: Z = Z.transpose(2, 0, 1) In [14]: print(Z.shape) (5, 37, 72)  Although we were able to create a 3-D array, Z, the location of the axis is little different from the convention we use (usually [t,z,y,x]). Using transpose function in NumPy, we can easily permute the order of axis.\nWhy on earth do we have to go through the transpose of the array? According to the docstring of tile, if the number of the dimension of the array is smaller than the length of the list in the second argument, NumPy prepends new axes to match the number of dimension. So a shape (3,) array is promoted to (1, 1, 3) for 3-D replication.  "
},
{
	"uri": "https://hajsong.github.io/ATM4110/python/array2/",
	"title": "Array operation 2",
	"tags": ["array", "numpy"],
	"description": "",
	"content": " So far we\u0026rsquo;ve learned how to make arrays, ask arrays to tell us about themselves, and manipulate arrays. But what scientists really want to do with arrays is make calculations with them. As a start, we discuss two ways to do exactly that. Method 1 uses for loops, in analogue to the use of loops in traditional Fortran programming, to do element-wise array calculations. Method 2 uses array syntax, where looping over array elements happens implicitly (this syntax is also found in Fortran 90 and later versions, IDL, etc.).\nGeneral array operation method 1: loops It may be straightforward to use iteration for the array operation looping through each element. Let\u0026rsquo;s look at the following example.\nimport numpy as np a = np.array([[2, 3.2, 5.5, -6.4], [3, 1, 2.1, 21]]) b = np.array([[4, 1.2, -4, 9.1], [6, 21, 1.5, -27]]) shape_a = np.shape(a) product_ab = np.zeros(shape_a, dtype='f') for i in range(shape_a[0]): for j in range(shape_a[1]): product_ab[i,j] = a[i,j] * b[i,j]  The flow of idea is\n Create an array with the same size of a or b. Iterate the slow varying direction Iterate the fast varying direction At each point, compute the multiplication  Now, let\u0026rsquo;s time how long the iteration takes to be done. Timing the process is quite simple in IPython because it provides magic functions: %timeit and %%timeit.\n%timeit takes the command in the following position. So it is useful to check how long(slow) the function is.\nOn the other hand, %%timeit takes multiple lines of code from the following line. So this is useful when we want to test the speed of the block of the code.\nIn this example, %%timeit is appropriate to measure the time.\nIn [1]: %%timeit ...: import numpy as np ...: a = np.array([[2, 3.2, 5.5, -6.4], ...: [3, 1, 2.1, 21]]) ...: b = np.array([[4, 1.2, -4, 9.1], ...: [6, 21, 1.5, -27]]) ...: shape_a = np.shape(a) ...: product_ab = np.zeros(shape_a, dtype='f') ...: for i in range(shape_a[0]): ...: for j in range(shape_a[1]): ...: product_ab[i,j] = a[i,j] * b[i,j] ...: 8.76 µs ± 47.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)  Try to time the iteration when we need to compute large arrays.\nnp.random.seed(0) # to initialize the random number generation a = np.random.randn(1000, 1000) b = np.random.randn(1000, 1000) shape_a = np.shape(a) product_ab = np.zeros(shape_a, dtype='f') for i in range(shape_a[0]): for j in range(shape_a[1]): product_ab[i,j] = a[i,j] * b[i,j]  In my machine, this takes 501 ms ± 7.83 ms per loop (mean ± std. dev. of 7 runs, 1 loop each).\nGeneral array operation method 2: array syntax The basic idea behind array syntax is that, much of the time, arrays interact with each other on a corresponding element basis, and so instead of requiring the user to write out the nested for loops explicitly, the loops and elementwise operations are done implicitly in the operator.\nConsider the first example. We can get product_ab using the multiplication operator.\na = np.array([[2, 3.2, 5.5, -6.4], [3, 1, 2.1, 21]]) b = np.array([[4, 1.2, -4, 9.1], [6, 21, 1.5, -27]]) product_ab = a * b  You can see that product_ab is exactly the same as above.\nUsing %%timeit, let\u0026rsquo;s measure the speed.\nIn [4]: %%timeit ...: a = np.array([[2, 3.2, 5.5, -6.4], ...: [3, 1, 2.1, 21]]) ...: b = np.array([[4, 1.2, -4, 9.1], ...: [6, 21, 1.5, -27]]) ...: product_ab = a * b ...: 3.75 µs ± 235 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)  How about the elementwise multiplication for large arrays?\nIn [5]: %%timeit ...: np.random.seed(0) ...: a = np.random.randn(1000, 1000) ...: b = np.random.randn(1000, 1000) ...: product_ab = a * b ...: 50 ms ± 375 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)  Avoiding iteration makes the calculation about 10 times faster! (And you have fewer lines of the code.)\nIn this example, we see that arithmetic operators are automatically defined to act elementwise when operands are NumPy arrays or scalars. (Operators do have function equivalents in NumPy, e.g., product, add, etc., for the situations where you want to do the operation using function syntax.) Additionally, the output array c is automatically created on assignment; there is no need to initialize the output array using zeros.\nHere is the table of arithmetic operator implemented in NumPy.\n   Operator Equivalent function Description     + np.add Addition (e.g., 1 + 1 = 2)   - np.subtract Subtraction (e.g., 3 - 2 = 1)   - np.negative Unary negation (e.g., -2)   * np.multiply Multiplication (e.g., 2 * 3 = 6)   / np.divide Division (e.g., 3 / 2 = 1.5)   // np.floor_divide Floor division (e.g., 3 // 2 = 1)   ** np.power Exponentiation (e.g., 2 ** 3 = 8)   % np.mod Modulus/remainder (e.g., 9 % 4 = 1)    Exercise: Compute the potential temperature Write a function that takes a 2-D array of pressures ($p$, in mbar) and a 2-D array of temperatures ($T$, in K) and returns the corresponding potential temperature, assuming a reference pressure ($p_0$) of 1000 mbar. Thus, the function’s return value is an array of the same shape and type as the input arrays. Recall that potential temperature \u0012is given by: $$ \\theta = T\\left(\\frac{p_0}{p}\\right)^{\\kappa}, $$ where $\\kappa$ = $R/cp$ = 2\u0026frasl;7 for a perfect diatomic gas like the atmosphere.\nIf you go with iteration, you might come up with the following.\ndef theta(p, T, p0 = 1000, kappa = 2./7.): ny, nx = p.shape output = np.zeros((ny, nx)) for j in range(ny): for i in range(nx): output[j,i] = T[j,i] * (p0 / p[j,i])**kappa return output  Using array operation,\ndef theta(p, T, p0 = 1000, kappa = 2./7.): return T * (p0 / p)**kappa  Now, let\u0026rsquo;s use the real atmospheric data which is the climatological air temperature at 500 mbar and compute the potential temperature.\nAfter getting the data from this link, let\u0026rsquo;s read it in IPython.\nimport numpy as np data = np.load('T_p.npz') T = data['T']+273.15 # convert the unit from degC to K p = data['P']  As the code becomes long, It is convenient to write a script to include all the functions and scripts.\nimport numpy as np \u0026quot;\u0026quot;\u0026quot; Compute the potential temperature using pressure (mbar) and Temperature (K) \u0026quot;\u0026quot;\u0026quot; def theta1(p, T, p0 = 1000, kappa = 2./7.): ny, nx = p.shape output = np.zeros((ny, nx)) for j in range(ny): for i in range(nx): output[j,i] = T[j,i] * (p0 / p[j,i])**kappa return output def theta2(p, T, p0 = 1000, kappa = 2./7.): return T * (p0 / p)**kappa data = np.load('T_p.npz') T = data['T']+273.15 # convert the unit from degC to K p = data['P'] potT1 = theta1(p, T) potT2 = theta2(p, T) print(np.array_equal(potT1, potT2))  The command in the print function determines whether two arrays are identical. The output is True, which is what we expect.\nIf you time the speed of theta1 and theta2, you can see that theta2 is much faster.\nIn [11]: %timeit pt1 = theta1(p, T) 27.3 ms ± 91.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each) In [12]: %timeit pt2 = theta2(p, T) 109 µs ± 817 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)  Using array operator is 250 times faster!\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/python/array3/",
	"title": "Array operation 3",
	"tags": ["Numpy", "array"],
	"description": "",
	"content": " We are going to look at more array operations using Numpy before diving into the linear algebra.\nFancy indexing NumPy offers more indexing facilities than regular Python sequences. In addition to indexing by integers and slices, as we saw before, arrays can be indexed by arrays of integers and arrays of booleans.\n\u0026gt;\u0026gt;\u0026gt; a = np.arange(12)**2 # the first 12 square numbers \u0026gt;\u0026gt;\u0026gt; i = np.array( [ 1,1,3,8,5 ] ) # an array of indices \u0026gt;\u0026gt;\u0026gt; a[i] # the elements of a at the positions i array([ 1, 1, 9, 64, 25]) \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; j = np.array( [ [ 3, 4], [ 9, 7 ] ] ) # a bidimensional array of indices \u0026gt;\u0026gt;\u0026gt; a[j] # the same shape as j array([[ 9, 16], [81, 49]])  The second example shows that Numpy returns the result in the same format of the input.\nWhen the indexed array a is multidimensional, a single array of indices refers to the first dimension of a. The following example shows this behavior by converting an image of labels into a color image using a palette.\n\u0026gt;\u0026gt;\u0026gt; palette = np.array( [ [0,0,0], # black ... [255,0,0], # red ... [0,255,0], # green ... [0,0,255], # blue ... [255,255,255] ] ) # white \u0026gt;\u0026gt;\u0026gt; image = np.array( [ [ 0, 1, 2, 0 ], # each value corresponds to a color in the palette ... [ 0, 3, 4, 0 ] ] ) \u0026gt;\u0026gt;\u0026gt; palette[image] # the (2,4,3) color image array([[[ 0, 0, 0], [255, 0, 0], [ 0, 255, 0], [ 0, 0, 0]], [[ 0, 0, 0], [ 0, 0, 255], [255, 255, 255], [ 0, 0, 0]]])  We can also give indexes for more than one dimension. The arrays of indices for each dimension must have the same shape.\n\u0026gt;\u0026gt;\u0026gt; a = np.arange(12).reshape(3,4) \u0026gt;\u0026gt;\u0026gt; a array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) \u0026gt;\u0026gt;\u0026gt; i = np.array( [ [0,1], # indices for the first dim of a ... [1,2] ] ) \u0026gt;\u0026gt;\u0026gt; j = np.array( [ [2,1], # indices for the second dim ... [3,3] ] ) \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; a[i,j] # i and j must have equal shape array([[ 2, 5], [ 7, 11]]) \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; a[i,2] array([[ 2, 6], [ 6, 10]]) \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; a[:,j] # i.e., a[ : , j] array([[[ 2, 1], [ 3, 3]], [[ 6, 5], [ 7, 7]], [[10, 9], [11, 11]]])  Another common use of indexing with arrays is the search of the maximum value of time-dependent series:\n\u0026gt;\u0026gt;\u0026gt; time = np.linspace(20, 145, 5) # time scale \u0026gt;\u0026gt;\u0026gt; data = np.sin(np.arange(20)).reshape(5,4) # 4 time-dependent series \u0026gt;\u0026gt;\u0026gt; time array([ 20. , 51.25, 82.5 , 113.75, 145. ]) \u0026gt;\u0026gt;\u0026gt; data array([[ 0. , 0.84147098, 0.90929743, 0.14112001], [-0.7568025 , -0.95892427, -0.2794155 , 0.6569866 ], [ 0.98935825, 0.41211849, -0.54402111, -0.99999021], [-0.53657292, 0.42016704, 0.99060736, 0.65028784], [-0.28790332, -0.96139749, -0.75098725, 0.14987721]]) \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; ind = data.argmax(axis=0) # index of the maxima for each series \u0026gt;\u0026gt;\u0026gt; ind array([2, 0, 3, 1]) \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; time_max = time[ind] # times corresponding to the maxima \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; data_max = data[ind, range(data.shape[1])] # =\u0026gt; data[ind[0],0], data[ind[1],1]... \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; time_max array([ 82.5 , 20. , 113.75, 51.25]) \u0026gt;\u0026gt;\u0026gt; data_max array([ 0.98935825, 0.84147098, 0.99060736, 0.6569866 ]) \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; np.all(data_max == data.max(axis=0)) True  np.argmax or np.argmin finds the index with the maximum or minimum values in the array, respectively. In case when you want to find the indices that satisfy the condition, np.where or np.nonzero can be useful.\n\u0026gt;\u0026gt;\u0026gt; x = np.arange(9.).reshape(3, 3) \u0026gt;\u0026gt;\u0026gt; np.where( x \u0026gt; 5 ) (array([2, 2, 2]), array([0, 1, 2])) \u0026gt;\u0026gt;\u0026gt; np.nonzero( x \u0026gt; 5 ) (array([2, 2, 2]), array([0, 1, 2])) \u0026gt;\u0026gt;\u0026gt; x[np.where( x \u0026gt; 3.0 )] # Note: result is 1D. array([ 4., 5., 6., 7., 8.]) \u0026gt;\u0026gt;\u0026gt; np.where(x \u0026lt; 5, x, -1) # Note: broadcasting. array([[ 0., 1., 2.], [ 3., 4., -1.], [-1., -1., -1.]]) \u0026gt;\u0026gt;\u0026gt; np.nonzero( x \u0026gt; 5 )  When three arguments are provided, np.where considers them as np.where(mask, a, b) which can be roughly thought of as a[i] if mask[i] else b[i]. This is what happened in the last example.\nLinear Algebra Vectors Before starting, let me claify the notation of vectors first. A vector of length n is just a sequence (or array, or tuple) of n numbers, which we write as $\\mathbf{x}=[x_1,\\dots,x_n]$. Then the sum of two vectors, $\\mathbf{x}$ and $\\mathbf{y}$, is $$ \\mathbf{x} + \\mathbf{y} = \\begin{bmatrix} x_1 \\newline x_2 \\newline \\vdots \\newline x_n \\end{bmatrix} + \\begin{bmatrix} y_1 \\newline y_2 \\newline \\vdots \\newline y_n \\end{bmatrix} = \\begin{bmatrix} x_1+y_1 \\newline x_2+y_2 \\newline \\vdots \\newline x_n+y_n \\end{bmatrix} $$ Scalar multiplication is expressed as $$ \\gamma \\mathbf{x} = \\begin{bmatrix} \\gamma x_1 \\newline \\gamma x_2 \\newline \\vdots \\newline \\gamma x_n \\end{bmatrix} $$\nAs we did last time, these operations can be done easily.\nx = np.ones(3) # Vector of three ones y = np.array((2, 4, 6)) # Converts tuple (2, 4, 6) into array print(x + y) print(4 * x)  Another way to do summation of two vector is\ndef add_vectors(v, w): return [vi + wi for vi, wi in zip(v, w)] add_vectors(x, y)  Similarly, the subtraction of vectors can be done using - or\ndef subtract_vectors(v, w): return [vi - wi for vi, wi in zip(v, w)] subtract_vectors(x, y)  The inner product of vectors $\\mathbf{x}$ and $\\mathbf{y}$ is defined as $$ \\mathbf{x}^T\\mathbf{y} = \\Sigma_{i=1}^{n}x_i y_i $$ Two vectors are called orthogonal if their inner product is zero.\nThe norm of a vector $\\mathbf{x}$ represents its \u0026ldquo;length\u0026rdquo; (i.e., its distance from the zero vector) and is defined as $$ ||\\mathbf{x}|| = \\sqrt{\\mathbf{x}^T\\mathbf{x}} $$\nIn Python, the inner product of $\\mathbf{x}$ and $\\mathbf{y}$ is\nnp.sum(x * y) # Inner product of x and y  and the norm of it is\nnp.sqrt(np.sum(x**2))  or\nnp.linalg.norm(x)  Can you write a short function for the inner product operation using a single line for iteration?   How about the norm calculation?   def sq_sum_of_squares(v): \u0026quot;\u0026quot;\u0026quot; sqrt(v1 * v1 + v2 * v2 ... + vn * vn)\u0026quot;\u0026quot;\u0026quot; return sum(vi ** 2 for vi in v)**(0.5)   \nMatrices Matrices are a neat way of organizing data for use in linear operations. For notation, an $n\\times k$ matrix $\\mathbf{A}$ is expressed as $$ \\mathbf{A} = \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\cdots \u0026amp; a_{1k} \\newline a_{21} \u0026amp; a_{22} \u0026amp; \\cdots \u0026amp; a_{2k} \\newline \\vdots \u0026amp; \\vdots \u0026amp; \u0026amp; \\vdots \\newline a_{n1} \u0026amp; a_{n2} \u0026amp; \\cdots \u0026amp; a_{nk} \\newline \\end{bmatrix} $$ If $n=k$, it is a square matrix. If $\\mathbf{A} = \\mathbf{A}^T$, it is a symmetric matrix.\nHere are some basic operations for matrices.\n\u0026gt;\u0026gt;\u0026gt; import numpy as np \u0026gt;\u0026gt;\u0026gt; a = np.array([[1.0, 2.0], [3.0, 4.0]]) \u0026gt;\u0026gt;\u0026gt; print(a) [[ 1. 2.] [ 3. 4.]] \u0026gt;\u0026gt;\u0026gt; a.transpose() array([[ 1., 3.], [ 2., 4.]]) \u0026gt;\u0026gt;\u0026gt; np.linalg.inv(a) array([[-2. , 1. ], [ 1.5, -0.5]]) \u0026gt;\u0026gt;\u0026gt; u = np.eye(2) # unit 2x2 matrix; \u0026quot;eye\u0026quot; represents \u0026quot;I\u0026quot; \u0026gt;\u0026gt;\u0026gt; u array([[ 1., 0.], [ 0., 1.]]) \u0026gt;\u0026gt;\u0026gt; j = np.array([[0.0, -1.0], [1.0, 0.0]]) \u0026gt;\u0026gt;\u0026gt; j @ j # matrix product array([[-1., 0.], [ 0., -1.]]) \u0026gt;\u0026gt;\u0026gt; np.trace(u) # trace 2.0 \u0026gt;\u0026gt;\u0026gt; np.diag(u) # Extract a diagonal array([1., 1.])  Linear problems One of the more common problems in linear algebra is solving a matrix-vector equation. Here is an example. We seek the vector $\\mathbf{x}$ that solves the equation $$ \\mathbf{y} = \\mathbf{A}\\mathbf{x}, $$ where $\\mathbf{y}$ is the observations and $\\mathbf{A}$ is the matrix containing explanatory variables). This problem imposes a set of linear equations, so the $i^{th}$ observation is written as $$ y_i = a_{i,1} x_1 + a_{i,2} x_2 + \\cdots + a_{i,k} x_k. $$\n1. When $n = k$ This problem has the same numbers of equations and unknowns. It means that there is a unique solution.\nA number called the determinant of the matrix tells us whether this matrix can be inverted or not. If the determinant of $\\mathbf{A}$ is not zero, then we say that $\\mathbf{A}$ is nonsingular. Perhaps the most important fact about determinants is that $\\mathbf{A}$ is nonsingular if and only if $\\mathbf{A}$ is of full column rank.\nThen the solution is just $\\mathbf{x} = \\mathbf{A}^{-1}\\mathbf{y}$.\nIn IPython,\nIn [2]: A = np.arange(9).reshape(3,3) In [3]: np.linalg.det(A) Out[3]: 0.0 In [4]: A = np.arange(9).reshape(3,3) + np.random.rand(3,3) In [5]: y = np.arange(3) In [6]: np.linalg.inv(A) @ y Out[6]: array([ 0.05905976, 0.79934638, -0.50158537]) In [7]: np.dot(np.linalg.inv(A),y) Out[7]: array([ 0.05905976, 0.79934638, -0.50158537])  2. When $n \\gt k$ In this case, there is no unique solution, but we can still seek a best approximation for $\\mathbf{x}$. After admitting that there must be errors associated with this linear problem, let\u0026rsquo;s introduce a vector $\\mathbf{n}$ that represents the error. Now the linear problem can be written as the following. $$ \\mathbf{y} = \\mathbf{A}\\mathbf{x} + \\mathbf{n}. $$ That the best estimate for the solution should lead to the smallest error. In other words, we want to pick $\\mathbf{x}$ that minimizes $$ J = \\mathbf{n}^T \\mathbf{n} = (\\mathbf{A}\\mathbf{x} - \\mathbf{y})^T(\\mathbf{A}\\mathbf{x} - \\mathbf{y}). $$ That $\\mathbf{x}$ satisfies $$ \\frac{\\partial J}{\\partial \\mathbf{x}} = 0 $$ Using\n$$ \\frac{\\partial \\left( \\mathbf{q}^T \\mathbf{r} \\right)}{\\partial \\mathbf{q}} = \\frac{\\partial \\left( \\mathbf{r}^T \\mathbf{q} \\right)}{\\partial \\mathbf{q}} = \\mathbf{r}, $$ $$ \\frac{\\partial \\left( \\mathbf{q}^T \\mathbf{q} \\right)}{\\partial \\mathbf{q}} =2\\mathbf{q}, $$ and $$ \\frac{\\partial\\left(\\mathbf{q}^T\\mathbf{A}\\mathbf{q}\\right)}{\\partial \\mathbf{q}} = \\left(\\mathbf{A} + \\mathbf{A}^T \\right)\\mathbf{q}, $$ we can obtain the solution as $$ \\mathbf{x} = \\left(\\mathbf{A}^T\\mathbf{A}\\right)^{-1}\\mathbf{A}^T\\mathbf{y} $$\n3. When $n \\lt k$ This is the case when there are fewer equations than unknowns, suggesting there is an infinite number of solutions.\n4. How to solve the linear problem in Python If you choose to compute the inverse of the matrix,\nx = np.linalg.inv(A.T @ A) @ A.T @ y  or\nx = np.dot(np.dot(np.linalg.inv(np.dot(A.T, A)), A.T), y).  It is generally not recommended to directly compute the inverse matrix. Numpy has a function to solve the linear problem.\nx = np.linalg.lstsq(A, y)  Exercise We did the exercise to compute the potential temperature using $$ \\theta = T \\left(\\frac{p_0}{p}\\right)^k $$ when the temperature, pressure and the reference pressure are given.\nAt this time, let\u0026rsquo;s to find the linear expression of $T$ and $p$ for the potential temperature. You can get the data from this link.\nFile I/O For Numpy\u0026rsquo;s native file format, one can use np.save and np.load. These functions were used in our previous exercise.\nWhen you want to save the array in the text file, np.savetxt does it for you. When you need to read the text file, you can use np.loadtxt.\na = np.array([1,2,3,4,5]) np.savetxt('out.txt',a) b = np.loadtxt('out.txt') print b  If the data are somehow formatted with either comma or space, you can use np.getfromtxt. When example.dat has\n1800 1 1 -6.1 -6.1 -6.1 1 1800 1 2 -15.4 -15.4 -15.4 1 1800 1 3 -15.0 -15.0 -15.0 1 1800 1 4 -19.3 -19.3 -19.3 1 1800 1 5 -16.8 -16.8 -16.8 1 1800 1 6 -11.4 -11.4 -11.4 1 1800 1 7 -7.6 -7.6 -7.6 1 1800 1 8 -7.1 -7.1 -7.1 1 1800 1 9 -10.1 -10.1 -10.1 1 1800 1 10 -9.5 -9.5 -9.5 1  in Python, data will be 10 by 7 ndarray if is created by np.genfromtxt\ndata = np.genfromtxt('example.dat')  "
},
{
	"uri": "https://hajsong.github.io/ATM4110/python/fileio/",
	"title": "Dealing with real data",
	"tags": ["python", "File IO"],
	"description": "",
	"content": " The atmospheric and oceanic sciences (AOS) are \u0026ldquo;data\u0026rdquo; intensive fields, whether data refers to observations or model output. Most of the analysis we do involve datasets, and so facilities for file input/output (i/o) are critical. Fortunately, Python has very robust facilities for file i/o, and we will be dealing with realistic datasets using Python.\nData in the text file Some data is not too big and stored in the text file. A good example is the CO$_2$ concentration in the atmosphere. In fact this is the famous \u0026ldquo;KEELING CURVE\u0026rdquo; Reading the text file is possible using the built-in function, open statement:\nf = open('co2_mm_mlo.txt','r') contents = f.readlines() f.close()  As you might guess, f is an object that many methods are attached. Do you remember how to list all available methods and attributes?\ndir(f)  You can see that close we used above is one of the methods. It is to flush and close the IO object. Once the file IO is closed, you can grab a handle on it. (You can not do anything with f unless you open the text file again.)\nThe method readlines goes through each line and save it as an element of the list, contents.\nIn [4]: contents[:10] Out[4]: ['# --------------------------------------------------------------------\\n', '# USE OF NOAA ESRL DATA\\n', '# \\n', '# These data are made freely available to the public and the\\n', '# scientific community in the belief that their wide dissemination\\n', '# will lead to greater understanding and new scientific insights.\\n', '# The availability of these data does not constitute publication\\n', '# of the data. NOAA relies on the ethics and integrity of the user to\\n', '# ensure that ESRL receives fair credit for their work. If the data \\n', '# are obtained for potential use in a publication or presentation, \\n'] . . . '# NOTE: In general, the data presented for the last year are subject to change, \\n', '# depending on recalibration of the reference gas mixtures used, and other quality\\n', '# control procedures. Occasionally, earlier years may also be changed for the same\\n', '# reasons. Usually these changes are minor.\\n', '#\\n', '# CO2 expressed as a mole fraction in dry air, micromol/mol, abbreviated as ppm\\n', '# (-99.99 missing data; -1 no data for #daily means in month)\\n', '#\\n', '# decimal average interpolated trend #days\\n', '# date (season corr)\\n', '1958 3 1958.208 315.71 315.71 314.62 -1\\n', '1958 4 1958.292 317.45 317.45 315.29 -1\\n', . . .  Well, this dataset has quite a few numbers of lines that are not values, and we want to exclude this header. Good news is that lines in the header start a special characters \u0026ldquo;#\u0026rdquo;. So we can determine whether the line is in the header or not by evaluating the first letter.\nThe string object has a method for this. It is called startswith.\nCO2 = [] for line in contents: if line.startswith('#') is False: print(line)  We can see that line is a string variable containing all the characters of each line. (Try type(line) to see the type of line.)\nWe are interested in the CO$_2$ concentration that is in the middle of the string line. So we need to somehow break this long string into pieces to extract the CO$_2$ concentration.\nPython has a host of string manipulation methods, built-in to string variables (a.k.a., objects), which are ideal for dealing with contents from text files. We will mention only a few of these methods. The split method of a string object takes a string and breaks it into a list using a separator. For instance:\nIn [9]: print(line) 2018 9 2018.708 405.51 405.51 409.02 29 In [10]: type(line) Out[10]: str In [11]: print(line.split()) ['2018', '9', '2018.708', '405.51', '405.51', '409.02', '29']  Finally, once we have the strings we desire, we can convert them to numerical types in order to make calculations.\nIf you loop through a list of strings, you can use the float and int functions on the string to get a number. For instance\nCO2 = [] for line in contents: if line.startswith('#') is False: values = line.split() CO2.append(float(values[3]))  For future purpose, we may want to save this array as another text file. To write a string to the file that is defined by the file object f, use the write method attached to the file object:\nf.write(astr)  Here, astr is the string you want to write to the file. Note that a newline character is not automatically written to the file after the string is written.\nTo write a list of strings to the file, use the writelines method:\nf.writelines(contents)  Here, contents is a list of strings.\nIn this example, we want to write CO$_2$ concentration to a new file, co2_keeling.txt.\nfileout = open('co2_keeling.txt', 'w') # open the text file to write fileout.writelines(str(CO2)) fileout.close()  If you view the text file, the values are stored in one line. We can save one value in each line as the following.\noutputstr = ['\\n'] * len(CO2) for i in range(len(CO2)): outputstr[i] = str(CO2[i]) + outputstr[i] fileout = open('co2_keeling.txt', 'w') # open the text file to write fileout.writelines(outputstr) fileout.close()  Data in the csv (comma-separated values) file You often find data in csv format. It is not very different from text files, but data values are separated with comma as the name infers. You can read csv format data as above, but slightly different.\nAs an example, I extracted the car accident statistics in 2017 where the incidents are sorted by the age of the drivers who caused the accident. Get the data from here.\nLet\u0026rsquo;s follow the steps in the previous example.\nf = open('caraccident_data.csv','r') contents = f.readlines() f.close()  The list variable contents has each line as its element. The first line that is saved in contents[0] contains the name of each column, but it is not the data values. So, I would do the following to read the total number of accident that is in the second column.\ntot = [] for line in contents[1:]: val = line.split(',') tot.append(float(val[1]))  When using the split method, we specified that the line could be separated by the comma.\nPython carries the module called csv to read and write csv files. That allows us to avoid doing tedious work of counting columns and rows.\nLet\u0026rsquo;s use the csv module.\nimport csv with open('caraccident_data.csv', 'r') as csvfile: csv_reader = csv.reader(csvfile) cnt = 0 for row in csv_reader: if cnt == 0: print(f'Column names are {\u0026quot;, \u0026quot;.join(row)}') else: print(f'Values are {\u0026quot;, \u0026quot;.join(row)}') cnt += 1  Rather than deal with a list of individual String elements, you can read CSV data directly into a dictionary. The csv module provides a method DictReader for us to organize the data as a dictionary variable.\nimport csv # Option 1 f = open('caraccident_data.csv', 'r') csv_reader = csv.DictReader(f) print(csv_reader.fieldnames) for row in csv_reader: print(f'Total number of {row[\u0026quot;type\u0026quot;]} is {row[\u0026quot;total\u0026quot;]}') f.close() # Option 2 with open('caraccident_data.csv', 'r') as csvfile: csv_reader = csv.DictReader(csvfile) for row in csv_reader: print(f'Total number of {row[\u0026quot;type\u0026quot;]} is {row[\u0026quot;total\u0026quot;]}')  Reading the CSV-type data using Pandas pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language. This package makes it even easier to handle cvs-type data files.\nimport pandas as pd data = pd.read_csv('caraccident_data.csv') print(data)  In IPython,\nIn [4]: whos Variable Type Data/Info --------------------------------- data DataFrame type tota\u0026lt;...\u0026gt;\\n\\n[6 rows x 10 columns] pd module \u0026lt;module 'pandas' from '/U\u0026lt;...\u0026gt;ages/pandas/__init__.py'\u0026gt; In [5]: print(data) type total less than 20 ... 61-64 greater than 65 unknown 0 accident 1143175 44501 ... 62373 115674 75485 1 death toll 4185 125 ... 313 838 2 2 casualty toll 1803325 65622 ... 93589 172330 148784 3 major casualty 96810 3605 ... 7353 14565 1687 4 minor casualty 581589 19729 ... 35310 55037 50046 5 other casualty 1124926 42288 ... 50926 102728 97051 [6 rows x 10 columns]  To see the name of columns, you can try\ndata.columns  There are two different ways to print out a column.\ndata.type data[\u0026quot;type\u0026quot;]  This is how you can grab the rows.\ndata.head(2) # prints the first 2 rows data.tail(1) # prints the last low  If you access the element, you can combine the name of the column and the number of the row.\nprint(data.type[3], data.total[3])  Using the indexing, we can get more than one rows.\nprint(data.total[1:3])  Selecting elements in a specific location is very similar to extracting elements from the array. There are two ways of doing it. When using loc method, you can specify the name of the columns.\ndata.loc[:2, ['61-64','greater than 65']]  Or you can use iloc for the location of the columns.\ndata.iloc[:1, 7:]  If you want to switch columns and rows,\ndata.T  pandas package provides a simple statistical tools attached to the variable.\ndata.describe()  Exercise: Extract statistical information from the dataset. One of the current issues is whether we regulate the permit for the senior drivers for the safety reasons. Let\u0026rsquo;s evaluate the data of the car accident in 2017 and see whether there is a statistical background for the regulation. Possible questions to be evaluated are.\n Are there more car accident caused by the drivers older than 60 than those with the age between 20-40? Do the accidents tend to be major by the drivers older than 60?  "
},
{
	"uri": "https://hajsong.github.io/ATM4110/",
	"title": "Programming in Meteorology",
	"tags": [],
	"description": "",
	"content": " MIDTERM : Science Hall 523\nProgramming in Meteorology This webpage is designed to serve the students enrolled for ATM4110, Programming in Meteorology.\nThis course will provide the programming foundation to perform the analysis and diagnostics of the big dataset in the atmospheric sciences. Upon the completion of this course, the students will be capable of analyzing the atmospheric data and extracting meaningful information from it.\nThis webpage is not in the final version but keeps evolving. I encourage students to visit this page frequently and be up to date.  \nObjective of this course  Introduce the programming environment for meteorology Handle the atmospheric data using programming language such as python Learn temporal/spatial/spectral analysis skills Solve problems using acquired skills in programming and produce meaningful results  A few examples that you can do after this course  Draw figures using atmospheric data on the map (source):  Post-process the data and plot the results (source):  Deal with global data for the climate-related research (Figure from the 5th IPCC report)   Instructor  Hajoon Song Office : Science Hall 544 Email : hajsong@yonsei.ac.kr Telephone : 02-2123-2579  Class  Tuesday 12-2 in Science Hall 523 Thursday 12-2 in Science Hall 603  Office hour  Tuesday 2-3 in Science Hall 544  Grading  Homework : 30% Midterm : 20% Final project : 40% Attendance and participation : 10%  Textbook When we go through python, I will follow the book, A Hands-On Introduction to Using Python in the Atmospheric and Oceanic Sciences (online version) If you have an issue with Python, you may find this online material be helpful.\nThe repository for the Jupyter Notebook files. I will upload the Jupyter Notebook files at Azure Notebooks\n"
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/anaconda/",
	"title": "Anaconda",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/array/",
	"title": "Array",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/basemap/",
	"title": "Basemap",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/cartopy/",
	"title": "Cartopy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/cat/",
	"title": "Cat",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/cd/",
	"title": "Cd",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/class/",
	"title": "Class",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/confidence-interval/",
	"title": "Confidence Interval",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/contour/",
	"title": "Contour",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/cp/",
	"title": "Cp",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/data-type/",
	"title": "Data Type",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/def/",
	"title": "Def",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/do/",
	"title": "Do",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/eofs/",
	"title": "Eofs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/file-io/",
	"title": "File Io",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/final/",
	"title": "Final",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/grep/",
	"title": "Grep",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/homework/",
	"title": "Homework",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/if/",
	"title": "If",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/imshow/",
	"title": "Imshow",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/jupyter-notebook/",
	"title": "Jupyter Notebook",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/linear-algebra/",
	"title": "Linear Algebra",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/linux/",
	"title": "Linux",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/list/",
	"title": "List",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/ls/",
	"title": "Ls",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/matplotlib/",
	"title": "Matplotlib",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/mkdir/",
	"title": "Mkdir",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/module/",
	"title": "Module",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/numpy/",
	"title": "Numpy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/object/",
	"title": "Object",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/objective/",
	"title": "Objective",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/oi/",
	"title": "Oi",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/pcolormesh/",
	"title": "Pcolormesh",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/plot/",
	"title": "Plot",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/precipitation/",
	"title": "Precipitation",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/python/",
	"title": "Python",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/rm/",
	"title": "Rm",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/spatial/",
	"title": "Spatial",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/statistics/",
	"title": "Statistics",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/tag1/",
	"title": "Tag1",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/tag2/",
	"title": "Tag2",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/temporal/",
	"title": "Temporal",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/tuple/",
	"title": "Tuple",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/unix/",
	"title": "Unix",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/vim/",
	"title": "Vim",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hajsong.github.io/ATM4110/tags/visualization/",
	"title": "Visualization",
	"tags": [],
	"description": "",
	"content": ""
}]